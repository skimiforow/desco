---
title: "DESCO - Knowledge Discovery - Prediction"
author: "1141074 - Sergio Silva | 1970400 - Pedro Neves | 1040706 - Sergio Castro"
date: "5/3/2018"
output:
  html_document: default
  editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(error = TRUE)
```

#Limpeza do ambiente

```{r Clean Environment, include=FALSE}
rm(list = ls())
```

#Bibliotecas necessárias

```{r include=FALSE}
library(lattice)
library(ggplot2)
library(caret)
library(C50)
library(data.table)
library(randomForest)
library(rfm)
library(lubridate)
library(gmodels)
library(e1071) #Nayve Bayes
library(dplyr) # Para criação dos valores categoricos a partir dos dados números do RFM

```






#Carregamento das tabelas de transaction

The	 RFM	 (recency,	 frequency	 and	 monetary)	 model	 is	 the	 most	 widely	 used	 to	characterize customers	 because	 of its	 simplicity	and	good	 predictive	 capabilities.	 "Recency"	 represents	 the	time	since	the	last	purchase,	a	lower	value	corresponding	to	a	higher	probability	of	the	customer	making	a	repeat	 purchase.	 "Frequency"	 denotes	 the	 number	 of	 purchases	 within	 a	 specified	 time	 period;	 higher	frequency	indicates	higher	loyalty.	"Monetary"	means	 the	amount	of	money	spent	over this	specified	 time	period,	a	higher	value	indicates a	customer	that	the	company	should	focus on [2].

Loading of the tables to create model RFM
```{r Carregamento}
keycols <- c('Store', 'Date', 'Time', 'TransactionID')

transactions = fread('DATA-CRM/TRANSACTION.dat')
setkeyv(transactions, keycols)

trans_items = fread('DATA-CRM/TRANSACTION_ITEM.dat')
setkeyv(trans_items, keycols)

```

##Fazer 'join' das duas tabelas e remover observações contendo datas inválidas


```{r Merge}
Result <- merge(transactions, trans_items, all = TRUE)
Result[, Date := as.Date(as.character.Date(Date),"%Y%m%d")]
Result <- na.omit(Result, cols = "Date")
```


## Gerar RFM Score com package rfm

Calcula 'Recency', 'Frequency' e 'Monetary' a partir duma tabela de transações
```{r RFM algorithm}
analysis_date <- as.Date("2015-01-01")

orders <- Result[, .(CardID, Date, Amount)]
rfm_result <- rfm_table_order(orders, CardID, Date, Amount, analysis_date, recency_bins = 5, frequency_bins = 5, monetary_bins = 5)

summary(rfm_result)
str(rfm_result)

rfm_bar_chart(rfm_result)

rfm_histograms(rfm_result)

# Correlacionar a Frequência com o valor gasto
rfm_fm_plot(rfm_result)

# Correlacionar a data da última compra com a frequência de compra
rfm_rf_plot(rfm_result)

rfm_heatmap(rfm_result)
```

O valor de "Recency" é classificado numa escala de 1 a 5 em que o valor 5 é atribuido aos clientes que compraram mais recentemente.
O valor de "Frequency" usa uma escala de 1 a 5 para indicar com 5 o cliente que compra com mais frequência
Por fim, o valor de Monetary classifica, também com uma escala de 1 a 5, indicando com 5 os clientes que gastam mais valor.

As divisões dos cestos é feita com o valor por defeito de 5, que divide em os valores a cada 20% dos dados.

Caso fosse necessério o calculo dos atributos do algoritmo RFM, poderíamos usar as seguintes formulas. As mesmas não foram usadas pois usamos o package RFM que nos dá este calculo automaticamente.

Cálculo "Manual" das três dimensões do RFM
```{r include=FALSE}
# Frequency
rfm_frequency <- Result[, .N, by = CardID]

# Monetary
rfm_monetary <- Result[ , .(Total = sum(Amount)), by = CardID]

# Recency
rfm_recency <- Result[, .(LatestOrder = max(Date)), by = CardID][, .(Recency = analysis_date - LatestOrder), by = CardID]
```


#1. Exploração e preparação dos dados



##Tabela CAMPAIGN.DAT
Carregamento da tabela CAMPAIGN.dat
```{r CAMPAIGN.dat}
campaign <- read.table("DATA-CRM/CAMPAIGN.dat", header = TRUE, sep = ",", dec = ",")
```

### Verificação dos dados da tabela campaign, tal como o número de colunas e linhas, bem como se os dados foram corretamente carregados.
```{r include=FALSE}
summary(campaign)
dim(campaign)
str(campaign)
```

###Verificar se a tabela possui dados nulos
```{r include=FALSE}
table(is.na(campaign))
unique(campaign)
table(duplicated(campaign))

```


## Tabela CARD.dat
```{r CARD.dat}
card <- read.table("DATA-CRM/CARD.dat", header = TRUE, sep = ",", dec = ",")
setDT(card)
```

### Verificação dos dados da tabela card, tal como o número de colunas e linhas, bem como se os dados foram corretamente carregados.
```{r include=FALSE}
summary(card)
dim(card)
str(card)
nrow(card[!complete.cases(card),])
```

### Tratar os dados nulos e errados nas colunas NumChildren e YoungestChild , pois tem valores negativos. No MaritalStatus há dados nulos que devem ser tratados também.

```{r Tratamento de dados}
card$NumChildren[card$NumChildren < 0] <- 0
table(card$NumChildren)
card$YoungestChild[card$YoungestChild < 0] <- 0
table(card$YoungestChild)


# Como existem observações que indicam ter filhos, mas depois o campo do número de filhos está a 0, decidimos alterar o atributo "HasChildren" para "N"
card[card$NumChildren == 0 & card$HasChildren == 'Y', .N]
card$HasChildren[card$NumChildren == 0] <- 'N'


# NumChildren>0 e HasChildren
card[card$NumChildren > 0 & card$HasChildren == 'N', .N]
card$HasChildren[card$NumChildren > 0] <- 'Y'

plot(card$NumChildren~card$HasChildren)

#TODO: o que colocar em YoungestChild quando HasChildren == 'N' e NumChildren == 0? 


# Verificamos que o MaritalStatus possui dados vazios
table(card$MaritalStatus)

card[MaritalStatus == "", MaritalStatus := "O"]
card$MaritalStatus <- droplevels(card$MaritalStatus)
```

### Verificar se a tabela Card possui dados nulos
```{r include=FALSE}
table(is.na(card))
unique(card)
table(duplicated(card))

```


#2. Pré-processamento dos dados

## Merge das tabelas

```{r juntar dados dos clientes}
df_card <- merge(card, rfm_result$rfm[,c(1,9)], by.x = 'CardID', by.y = 'customer_id')

df_card <- merge(df_card, campaign, by = 'CardID')

df_card[, CardStartDate := as.Date(as.character.Date(CardStartDate),"%Y%m%d")]

df_card[, DateOfBirth := as.Date(as.character.Date(DateOfBirth),"%Y%m%d")]

```

```{r criar as colunas com idade e anos de cliente}
# Criar a idade do cliente
yr = duration(num = 1, units = "years")
df_card[, age := round(interval(DateOfBirth, analysis_date)/yr,digits = 0)][]

# Anos de clientes
df_card[, clientYears := round(interval(CardStartDate, analysis_date)/yr,digits = 0)][]

summary(df_card)
```

```{r retirar id e código postal, CardStartDate e DateOfBirth}

df_card <- df_card[, c(2,3,6,8:15)]

# Mudar o atributo objetivo para o fim da tabela
df_card <- df_card[, c(1:8,10,11,9)]

str(df_card)


df_card$Gender <- factor(df_card$Gender, levels = c("F", "M"), labels = c("Feminino", "Masculino"))
df_card$MaritalStatus <- factor(df_card$MaritalStatus, levels = c("M", "S", "O"), labels = c("Casado", "Solteiro", "Outro"))
df_card$HasChildren <- factor(df_card$HasChildren, levels = c("Y", "N"), labels = c("Sim","Não"))
df_card$Responded <- factor(df_card$Responded, levels = c(TRUE, FALSE), labels = c("Sim","Não"))

```


## Visualização dos dados

```{r}

# Verificar a percentagem de clientes que responderam à campanha
barplot(table(df_card$Responded), ylim = c(0,10000), main = "Responded")

prop.table(table(df_card$Responded))*100


```



#3. Criação de modelos de Data-Mining e avaliação dos mesmos
```{r include=FALSE,eval=FALSE}
#Função para avaliação dos modelos e data frame para guardar os dados

allcrosstabmeasures <- function (tst_labels, pred_labels, modelname=""){
  if (length(unique(tst_labels)) == length(unique(pred_labels))) {
    ctmatrix <- CrossTable(tst_labels,pred_labels,prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE, dnn = c("Real","Predicted"))
    accuracy <- sum(diag(ctmatrix$t))/sum(ctmatrix$t)
    recall <- ctmatrix[[1]][1,1]/sum(ctmatrix[[1]][1,]) #TPR Recall
    precision <- ctmatrix[[1]][1,1]/sum(ctmatrix[[1]][,1])
    fpr <- ctmatrix[[1]][2,1]/sum(ctmatrix[[1]][2,])
    f1 <- 2*precision*recall/(precision+recall)
    pre <- (sum(ctmatrix[[1]][1,])/sum(ctmatrix$t)*sum(ctmatrix[[1]][,1])/sum(ctmatrix$t)) + (sum(ctmatrix[[1]][2,])/sum(ctmatrix$t)*sum(ctmatrix[[1]][,2])/sum(ctmatrix$t))
  kappa <- (accuracy - pre) / (1-pre)
  data.frame(model=modelname,accuracy=round(accuracy,digits = 3),recall=round(recall,digits = 3),precision=round(precision,digits = 3),f1=round(f1,digits = 3), kappa=round(kappa,digits = 3),fpr=round(fpr,digits = 3))
  } else {
    stop("Erro na construção do modelo")
  }
}


# Declara um data frame para guardar os dados estatisticos

results.df <- data.frame(model = character(),
                         accuracy = double(),
                         recall = double(),
                         precision = double(),
                         f1 = double(),
                         kappa = double(),
                         fpr = double(),
                         stringsAsFactors = FALSE)

```


## Devido à taxa de Sim no atributo Responded ser inferior a 20%, foi necessário efetuar um Oversamppling dos dados positivos para equilibrar os mesmos.
```{r include=FALSE}
# Holdout stratified
   
set.seed(123)

#create of stratified train/test partitions
train.idx <- createDataPartition(df_card$Responded, p = 0.7, list = F)

trainSet <- df_card[ train.idx, ]
tstSet <-   df_card[-train.idx, ]

# Criar o oversampling para resolver o problema dos dados desbalanceados.
oversampling <- trainSet[ which(trainSet$Responded=='Sim'),]
trainSet <- rbind(trainSet,oversampling)
trainSet <- rbind(trainSet,oversampling)
table(trainSet$Responded)
summary(trainSet)

table(trainSet$Responded)
round(prop.table(table(trainSet$Responded))*100, digits = 2)

train_labels <- trainSet$Responded
tst_labels <- tstSet$Responded

round(prop.table(table(train_labels))*100, digits = 2)
round(prop.table(table(tst_labels))*100, digits = 2)

ncols <- dim(trainSet)[2]
ctrl <- trainControl(method = "cv", number = 10)
```



```{r C5.0}
set.seed(123)

modelLookup(model = "C5.0") # ver o que o model pede

C5Model <- C5.0(Responded~.,data = trainSet)

summary(C5Model)

C5Predict <- predict(C5Model,newdata = tstSet,type = "class")

results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,C5Predict,"C5.0 Classif."))
results.df
```


```{r C5.0 com funcao treino}
##################################################################################

# C5.0 com funcão treino


#grade de parametros para otimizar o algoritmo

grid <- expand.grid(winnow = c(TRUE,FALSE), trials = c(1,2,10,15,20), model = "tree")
grid


C5model <- train(Responded~.,data = trainSet,
                 method = 'C5.0',
                 metric = 'Accuracy',
                 trControl = ctrl,
                 tuneGrid = grid)
C5model

trellis.par.set(caretTheme())
plot(C5model)


C5pred <- predict(C5model, tstSet)

table(C5pred)

results.df <- rbind(results.df, allcrosstabmeasures(tst_labels, C5pred, "C5.0 with train caret "))
results.df
```



```{r C5.0 with adaptative boosting}
##################################################################################

# C5.0 with adaptative boosting

set.seed(123)

boost100.model <- C5.0(x = trainSet[,c(1:10)],trainSet$Responded, trials = 100)

summary(boost100.model)

boost100.pred <- predict(boost100.model,tstSet)

results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,boost100.pred,"C5.0 with adaptative boosting "))
results.df

##################################################################################
```




```{r Naive Bayes}
##################################################################################

# Naive Bayes

set.seed(123)

Bayesmodel <-train(trainSet[,c(1:10)], y = trainSet$Responded,
                    method = "nb",
                    tuneGrid = data.frame(fL=1,usekernel=FALSE,adjust=1),
                    trControl = ctrl)

Bayespred <- predict(Bayesmodel,tstSet)

results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,Bayespred,"Naive Bayes"))
results.df

##################################################################################
```

```{r Random Forest}


set.seed(123)

control <- trainControl(method = "repeatedcv", number = 10, repeats = 3, search  ="grid")

mtry <- round(sqrt(ncol(trainSet)),0)

rfmodel <- train(Responded~.,
                 data=trainSet,
                 method = "rf",
                 tuneGrid = expand.grid(.mtry=1:15),
                 trControl=control,
                 ntree=100)


print(rfmodel)
plot(rfmodel)

varImp(rfmodel)

rfpredict <- predict(rfmodel,newdata = tstSet,type = 'raw')
results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,rfpredict,"Random Forest"))
results.df
```


# Logistic regression
```{r}
crtl <- trainControl(method = 'cv', number = 3)

set.seed(123)

glmodel <- train(Responded~.,
                 data= trainSet,
                 method = 'glm',
                 trControl = crtl)

summary(glmodel)

glmpred <- predict(glmodel, newdata = tstSet)
results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,glmpred,"Logistic regression"))
results.df
```

#TODO: está a dar erro
# K-Nearest neighbours
```{r K-Nearest neighbours}
set.seed(123)

knnmodel <- train(Responded~.,
                  data = trainSet,
                  method = 'knn',
                  tuneGrid = expand.grid(k = seq(1,100,2)),
                  metric = 'Accuracy',
                  trControl = crtl)

knnpred <- predict(knnmodel,newdata = tstSet, type = "raw")

results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,knnpred,"K-Nearest neighbours"))
results.df
```


#TODO: está a dar erro
# Support Vector Machine (SVM) LINEAR
```{r Support Vector Machine (SVM) LINEAR}
set.seed(123)

svmodel <- train(Responded~.,
                 data = trainSet,
                 method = 'svmLinear',
                 metric = 'Accuracy',
                 maximize = FALSE,
                 tuneLength = 15,
                 trControl = crtl)

svpred <- predict(svmodel,newdata = tstSet)

results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,svpred,"Support Vector Machine (SVM) - Linear"))
results.df
```

#TODO: está a dar erro
# Support Vector Machine (SVM) RADIAL
```{r Support Vector Machine (SVM) RADIAL}
set.seed(123)
grid <- expand.grid(sigma = c(.01,.015, 0.2), C = c(0.75, 0.9, 1,1.1,1.25))
svmodelradial <- train(Responded~.,
                 data = trainSet,
                 method = 'svmRadial',
                 PreProc = c("center","scale"),
                 metric = 'Accuracy',
                 maximize = FALSE,
                 tuneGrid = grid,
                 trControl = crtl)

svpredradial <- predict(svmodelradial,newdata = testSet)

results.df <- rbind(results.df,allcrosstabmeasures(test_Labels,svpredradial,"Support Vector Machine (SVM) - Radial"))
results.df
```

# neural network
```{r neural network}
set.seed(123)

nnetGrid <- expand.grid(.decay = c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.1), size = (1:10))
nnetGrid <- expand.grid(decay = c(0, 0.01, .1),
                        size = c(1:10))

nnmodel <- train(Responded~.,
                 data = trainSet,
                 method = 'nnet',
                 metric = 'Accuracy',
                 tuneGrid = nnetGrid,
                 trace = FALSE,
                 maxit = 1000,
                 preProc = c("center","scale"),
                 trControl = crtl)

nnpred <- predict(nnmodel,newdata = tstSet)

results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,nnpred,"Neural network"))
results.df
```

#Analise do resultado dos modelos de classificação.

"True positive" e "true negative" são as observações que foram corretamente previstas. a ideia e minimizar os "false positive" e os "false negative", sendo que o mais importante é reduzir o risco de perder negócio, com a identificação de clientes que não iriam responder à campanha quando o resultado era positivo.

True Positives (TP) - Estes valores são valores da classe "Sim" que foram corretamente previstos.

True Negatives (TN) - São os valores da classe "Não" que foram corretamente previstos como "Não".

Os falsos positivos e os falso negativos são valores que ocorrem quando o modelo classifica as classes de forma contrária ao atual.

False Positives (FP) - As ocorrências em que se obtem "Sim" na previsão do modelo mas na realidade são "Não".

False Negatives (FN) - Ao contrário dos falsos positivos, aqui a previsão originada é o "Não" mas deveria ter sido "Sim".

Com estes paramtros da matriz de confusão, conseguimos avaliar vários parametros dos modelos, tal como, Accuracy, Precision, Recall e F1 score.


A Accuracy é uma medida de performance do modelo que é um rácio entre os valores corretamente previstos tendo em conta o número total de observações. Esta medida é boa na avaliação de modelos equilibrados/balanceados, modelos que se obtem o mesmo número de falso positivos e falso negativos. Desta forma é necessário avaliar outras medidas.

Accuracy = TP+TN/TP+FP+FN+TN

Precision - Indica o rácio de valores positivos corretamente classificados tendo em conta o total de observações positivas.

Precision = TP/TP+FP

Recall (Sensitivity) - Indica o rácio de observações corretamente previstas e todas as observações da classe. Vais indicar quantos dos "Sim" foram corretamente classificados.

Recall = TP/TP+FN

F1 score - Esta medida é uma média pesada entre a Precision e a Recall, tendo em conta ambos os falsos positivos e os falsos negativos. Esta medida poderá ser a mais acertada, principalmente no caso de termos classes desbalanceadas. 

F1 Score = 2*(Recall * Precision) / (Recall + Precision)

Resultados obtidos correndo os algoritmos classificação:

                           model accuracy recall precision    f1 kappa   fpr
1                  C5.0 Classif.    0.660  0.392     0.259 0.312 0.099 0.274
2         C5.0 with train caret     0.731  0.321     0.317 0.319 0.151 0.169
3 C5.0 with adaptative boosting     0.704  0.352     0.291 0.319 0.132 0.210
4               C5.0 with costs     0.731  0.321     0.317 0.319 0.151 0.169
5                    Naive Bayes    0.699  0.202     0.215 0.208 0.022 0.180
6                  Random Forest    0.762  0.159     0.301 0.208 0.083 0.090
7            Logistic regression    0.714  0.171     0.214 0.190 0.019 0.154
8                 Neural network    0.654  0.328     0.231 0.271 0.053 0.267

```{r Avaliação dos modelos}

results.df

barplot(results.df$f1, col = c(1:9), main = "Avaliação F1", ylim = c(0,0.60))
legend("topright", levels(results.df$model), bty = "n", fill = c(1:length(results.df$model)))

barplot(results.df$precision, col = c(1:9), main = "Avaliação Precision", ylim = c(0,0.60))
legend("topright", levels(results.df$model), bty = "n", fill = c(1:length(results.df$model)))

barplot(results.df$recall, col = c(1:9), main = "Avaliação Recall", ylim = c(0,0.60))
legend("topright", levels(results.df$model), bty = "n", fill = c(1:length(results.df$model)))


barplot(results.df$accuracy, col = c(1:9), main = "Avaliação Accuracy", ylim = c(0,0.90))
legend("topright", levels(results.df$model), bty = "n", fill = c(1:length(results.df$model)))

#Best Recall
results.df[order(results.df$recall, results.df$precision, decreasing = TRUE),]

#Balance between recall and precision - f1
results.df[order(results.df$f1, decreasing= TRUE),]


#Best Accuracy
results.df[order(results.df$accuracy, decreasing= TRUE),]

```

### SEGUNDA CLASSIFICAÇÃO ###

# Alterar o RFM para dados categoricos para avaliação do tipo de cliente
Ao categoriazar os clientes pelo valor de RFM atribuido, podemos tentar prever o tipo dos clientes novos. Os factores da classe a prever foram criados seguindo a seguinte regra:

Com um score de RFM inferior ou igual a 233, consideramos um cliente esporádico.
Com um score de RFM entre 234 e 443, consideramos um cliente regular.
Com um score de RFM superior ou igual a 444, consideramos um cliente frequente.



```{r Criacao de variaveis categoricas a partir dos dados numericos do RFM}

table(df_card$rfm_score)
hist(df_card$rfm_score,breaks = seq(min(df_card$rfm_score), max(df_card$rfm_score), length.out = df_card$rfm_score))

summary(df_card)


df_card$rfm_score_cat <- case_when(df_card$rfm_score <= 233 ~ 'Sporadically',
                  between(df_card$rfm_score, 234, 443) ~ 'Regular',
                  df_card$rfm_score >= 444 ~ 'Frequent'
                  )

df_card$rfm_score_cat <- as.factor(df_card$rfm_score_cat)

summary(df_card)

new_df_card <- df_card[,c(1:7,9,10,12)]
str(new_df_card)
attach(new_df_card)

```

# Declarar um data frame para guardar os dados estatísticos para a segunda classificação, definida por um clustering manual na classe RFM.

Este clustering manual vai-nos permitir ter um melhor conhecimento dos novos clientes, prevendo a sua possível categoria de cliente.

```{r}

results.new_df <- data.frame(model = character(),
                         accuracy = double(),
                         recall = double(),
                         precision = double(),
                         f1 = double(),
                         kappa = double(),
                         fpr = double(),
                         stringsAsFactors = FALSE)
```


## Holdout stratified
```{r Holdout stratified from second classification}


set.seed(123)

table(new_df_card$rfm_score_cat)
round(prop.table(table(new_df_card$rfm_score_cat))*100, digits = 2)


#create of stratified train/test partitions
train.idx <- createDataPartition(new_df_card$rfm_score_cat, p = 0.7, list = F)

trainSet <- new_df_card[ train.idx, ]
tstSet <-   new_df_card[-train.idx, ]

table(trainSet$rfm_score_cat)
round(prop.table(table(trainSet$rfm_score_cat))*100, digits = 2)

train_labels <- trainSet$rfm_score_cat
tst_labels <- tstSet$rfm_score_cat

round(prop.table(table(train_labels))*100, digits = 2)
round(prop.table(table(tst_labels))*100, digits = 2)

ncols <- dim(trainSet)[2]
ctrl <- trainControl(method = "cv", number = 10)
```




```{r C5.0  segunda classificação}
set.seed(123)

modelLookup(model = "C5.0") # ver o que o model pede

C5Model <- C5.0(rfm_score_cat~.,data = trainSet)

summary(C5Model)

C5Predict <- predict(C5Model,newdata = tstSet,type = "class")

results.new_df <- rbind(results.new_df,allcrosstabmeasures(tst_labels,C5Predict,"C5.0 Classif."))
results.new_df
```

```{r C5.0 with adaptative boosting segunda classificação}
set.seed(123)

boost100.model <- C5.0(rfm_score_cat~.,data = trainSet, trials = 100)

summary(boost100.model)

boost100.pred <- predict(boost100.model,tstSet)

results.new_df <- rbind(results.new_df,allcrosstabmeasures(tst_labels,boost100.pred,"C5.0 with adaptative boosting "))
results.new_df
```


#TODO: Está a dar erro porque não consegue prever registo com o atributo frequente.
```{r C5.0 com funcao treino  segunda classificação}
##################################################################################

#grade de parametros para otimizar o algoritmo
grid <- expand.grid(winnow = c(TRUE,FALSE), trials = c(1,2,10,15,20), model = "tree")
grid


C5model <- train(rfm_score_cat~.,data = trainSet,
                 method = 'C5.0',
                 metric = 'Accuracy',
                 trControl = ctrl,
                 tuneGrid = grid)
C5model

trellis.par.set(caretTheme())
plot(C5model)


C5pred <- predict(C5model, tstSet)

table(C5pred)

results.new_df <- rbind(results.new_df, allcrosstabmeasures(tst_labels, C5pred, "C5.0 with train caret "))
results.new_df
```


```{r Naive Bayes segunda classificação}
##################################################################################

# Naive Bayes

set.seed(123)

Bayesmodel <-train(rfm_score_cat~.,data = trainSet,
                    method = "nb",
                    tuneGrid = data.frame(fL=1,usekernel=FALSE,adjust=1),
                    trControl = ctrl)

Bayespred <- predict(Bayesmodel,tstSet)

results.new_df <- rbind(results.new_df,allcrosstabmeasures(tst_labels,Bayespred,"Naive Bayes"))
results.new_df

##################################################################################
```


```{r K-Nearest neighbours segunda classificação}
set.seed(123)

knnmodel <- train(rfm_score_cat~.,
                  data = trainSet,
                  method = 'knn',
                  tuneGrid = expand.grid(k = seq(1,100,2)),
                  metric = 'Accuracy',
                  trControl = crtl)

knnpred <- predict(knnmodel,newdata = tstSet, type = "raw")
table(knnpred)

results.new_df <- rbind(results.new_df,allcrosstabmeasures(tst_labels,knnpred,"K-Nearest neighbours"))
results.new_df
```

#TODO: Está a dar erro porque não consegue prever registos com o atributo frequente.
```{r Support Vector Machine (SVM) LINEAR segunda classificação}
set.seed(123)

svmodel <- train(rfm_score_cat~.,
                 data = trainSet,
                 method = 'svmLinear',
                 metric = 'Accuracy',
                 maximize = FALSE,
                 tuneLength = 15,
                 trControl = crtl)

svpred <- predict(svmodel,newdata = tstSet)
table(svpred)

results.new_df <- rbind(results.new_df,allcrosstabmeasures(tst_labels,svpred,"Support Vector Machine (SVM) - Linear"))
results.new_df
```


```{r Support Vector Machine (SVM) RADIAL segunda classificação}
set.seed(123)
grid <- expand.grid(sigma = c(.01,.015, 0.2), C = c(0.75, 0.9, 1,1.1,1.25))
svmodelradial <- train(rfm_score_cat~.,
                 data = trainSet,
                 method = 'svmRadial',
                 PreProc = c("center","scale"),
                 metric = 'Accuracy',
                 maximize = FALSE,
                 tuneGrid = grid,
                 trControl = crtl)

svpredradial <- predict(svmodelradial,newdata = tstSet)
table(svpredradial)

results.new_df <- rbind(results.new_df,allcrosstabmeasures(tst_labels,svpredradial,"Support Vector Machine (SVM) - Radial"))
results.new_df
```


#TODO: Está a dar erro porque não consegue prever registos com o atributo frequente.
```{r neural network segunda classificação}
set.seed(123)

nnetGrid <- expand.grid(.decay = c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.1), size = (1:10))
nnetGrid <- expand.grid(decay = c(0, 0.01, .1),
                        size = c(1:10))

nnmodel <- train(rfm_score_cat~.,
                 data = trainSet,
                 method = 'nnet',
                 metric = 'Accuracy',
                 tuneGrid = nnetGrid,
                 trace = FALSE,
                 maxit = 1000,
                 preProc = c("center","scale"),
                 trControl = crtl)

nnpred <- predict(nnmodel,newdata = tstSet)
table(nnpred)

results.new_df <- rbind(results.new_df,allcrosstabmeasures(tst_labels,nnpred,"Neural network"))
results.new_df
```


# Avaliação dos modelos para previsão do atributo de cliente baseado no RFM.

                                  model accuracy recall precision    f1 kappa   fpr
1                         C5.0 Classif.    0.376  0.103     0.308 0.154 0.248 0.097
2        C5.0 with adaptative boosting     0.376  0.103     0.308 0.154 0.248 0.097
3                           Naive Bayes    0.379  0.004     0.174 0.008 0.251 0.010
4                  K-Nearest neighbours    0.374  0.044     0.289 0.076 0.223 0.044
5 Support Vector Machine (SVM) - Radial    0.364  0.064     0.260 0.103 0.203 0.071

