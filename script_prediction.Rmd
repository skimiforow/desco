---
title: "DESCO - Knowledge Discovery - Prediction"
author: "1141074 - Sergio Silva | 1970400 - Pedro Neves | 1040706 - Sergio Castro"
date: "5/3/2018"
bibliography: bibliography.bib
output:
  html_document: default
  editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(error = TRUE)
```

Este documento é focado na parte do processo relativo à classificação de clientes, o objetivo é futuramente conseguirmos prever tendo em conta novos clientes, qual a reposta que se irá ter às campanhas. 

Numa primeira fase vamos esclher que dados dos clientes vamos analisar e como analisar, bem como, algum tipo de tratamento que seja possível efetuar.


```{r Limpeza das variáveis de ambiente, include=FALSE}
rm(list = ls())
```


```{r Bibliotecas necessarias, include=FALSE}
library(lattice)
library(ggplot2)
library(caret)
library(C50)
library(data.table)
library(randomForest)
library(rfm)
library(lubridate)
library(gmodels)
library(e1071) ##Nayve Bayes
library(dplyr) ## Para criacao dos valores categoricos a partir dos dados números do RFM

```


## Carregamento das tabelas de **TRANSACTION.dat** e **TRANSACTION_ITEM.dat**

#### Pré-processamento para fazer o merge das duas tabelas, definindo uma chave em ambas as tabelas para efetuar o merge.
```{r Pre-processamento para fazer o merge das duas tabelas}

#Definir a key para efetuar o merge
keycols <- c('Store', 'Date', 'Time', 'TransactionID')

#Tabela TRANSACTION.dat
transactions = fread('DATA-CRM/TRANSACTION.dat')
setkeyv(transactions, keycols)

#Tabela TRANSACTION_ITEM.dat
trans_items = fread('DATA-CRM/TRANSACTION_ITEM.dat')
setkeyv(trans_items, keycols)

```

#### Efetuar 'join' das duas tabelas e remover as observacões contendo datas inválidas
```{r Merge das tabelas}
# Execução do merge
Result <- merge(transactions, trans_items, all = TRUE)

# Tratamento das datas para formato de data
Result[, Date := as.Date(as.character.Date(Date),"%Y%m%d")]

# verificar possíveis erros neste tratamento
Result <- na.omit(Result, cols = "Date")
```


#### Gerar RFM Score com package rfm

O modelo **RFM** (*Recency*, *Frequency*, *Monetary*) é um modelo muito usado para a categorização de clientes, por causa da sua simplicidade e boa capacidade de previsão. 

1. O atributo **Recency** refere-se ao tempo desde a última compra, um valor superior refere-se a uma maior probablidade do cliente efetuar uma compra brevemente.

2. O atributo **Frequency** indica o número de compras efetuadas pelo cliente no período de análise, um valor maior indica uma frequência maior.

3. Por fim, o atributo **Monetary** mostra a quantidade de dinheiro gasta durante o período específico, onde um valor superior indica um cliente que gastou mais dinheiro.

Por defeito, o RFM atribui valores de 1 a 5 e apesar destes valores poderem ser configuráveis, consideramos que são suficientes para avaliar os dados dos clientes. As divisões dos cestos feita com o valor de 5, divide os valores a cada 20% dos dados.
[Ref. @Birant2011]

Calculo do *Recency*, *Frequency*, *Monetary* a partir da tabela de transacões, resultado do *merge* anterior.
```{r RFM algorithm}

# Data definida para a análise, foi defenida a data de 01-01-2015 pois como os dados são de 2014, faria sentido aplicar esta análise nesta altura. 
analysis_date <- as.Date("2015-01-01")


#Aplicação do package *rfm*, com os dados necessário de CardID, Data da última compra e Amount
orders <- Result[, .(CardID, Date, Amount)]
rfm_result <- rfm_table_order(data = orders, customer_id = CardID, order_date = Date, revenue = Amount, analysis_date = analysis_date, recency_bins = 5, frequency_bins = 5, monetary_bins = 5)
```

Análise dos dados obtidos na aplicação do algotirtmo de **RFM** do package *rfm*
```{r RFM algorithm analysis, include=FALSE}

# Verificação visual dos dados
summary(rfm_result)
str(rfm_result)

# Examinar a distribuição dos resultados de monetary para diferentes combinações de resultados de frequency e recency.
rfm_bar_chart(rfm_result)

# Distribuição dos Histogramas para as 3 medidas de Recency, Frequency e Monetary
rfm_histograms(rfm_result)

## Correlacionar a data da última compra com a frequência de compra
rfm_rm_plot(rfm_result, point_color = "blue", xaxis_title = "Monetary",
yaxis_title = "Recency", plot_title = "Recency vs Monetary")

## Correlacionar a Frequência com o valor gasto
rfm_fm_plot(rfm_result, point_color = "blue", xaxis_title = "Monetary",
yaxis_title = "Frequency", plot_title = "Frequency vs Monetary")

## Correlacionar a data da última compra com o valor gasto
rfm_rf_plot(rfm_result, point_color = "blue", xaxis_title = "Frequency",
yaxis_title = "Recency", plot_title = "Recency vs Frequency")

## Heat Map de relacionamento das três variáveis
rfm_heatmap(rfm_result, plot_title = "RFM Heat Map", plot_title_justify = 0.5,
xaxis_title = "Frequency", yaxis_title = "Recency",
legend_title = "Mean Monetary Value", brewer_n = 5,
brewer_name = "PuBu")

```

Caso fosse necessário o calculo dos atributos do algoritmo RFM, poderíamos usar as seguintes formulas. As mesmas nao foram usadas pois usamos o package RFM que nos efetua estes calculo automaticamente. [Ref. @Fan2016]

Calculo "Manual" das três dimensões do RFM
```{r include=TRUE, eval=FALSE}
## Frequency
rfm_frequency <- Result[, .N, by = CardID]

## Monetary
rfm_monetary <- Result[ , .(Total = sum(Amount)), by = CardID]

## Recency
rfm_recency <- Result[, .(LatestOrder = max(Date)), by = CardID][, .(Recency = analysis_date - LatestOrder), by = CardID]
```


##1. Exploracao e preparacao dos dados

Nesta fase e após termos os valores de *RFM*, vamos iniciar o processo de análise e preparação dos dados para a fase de classificação.

#### Tabela CAMPAIGN.DAT
Após o carregamento da tabela *CAMPAIGN.dat*
```{r CAMPAIGN.dat}
campaign <- read.table("DATA-CRM/CAMPAIGN.dat", header = TRUE, sep = ",", dec = ",")
```

É necessário efetuar a verificacao dos dados da tabela *CAMPAIGN.dat*, tal como o número de colunas e linhas, bem como se os dados foram corretamente carregados.
```{r include=FALSE}
summary(campaign)
dim(campaign)
str(campaign)
```

Verificar se a tabela possui dados nulos, o que não acontece.
Esta tabela é muito simples e não houve dados a corrigir.
```{r include=FALSE}
table(is.na(campaign))
unique(campaign)
table(duplicated(campaign))

```

#### Tabela CARD.dat
Carregamento da tabela *CARD.dat* bem como a sua transformação para *Data Table* para facilitar o tratamento posteriormente.
```{r CARD.dat}
card <- read.table("DATA-CRM/CARD.dat", header = TRUE, sep = ",", dec = ",")
setDT(card)
```

Verificacao dos dados da tabela card, tal como o número de colunas e linhas, bem como se os dados foram corretamente carregados.
Podemos verificar alguns dados como *NumChildren* e *YoungestChild* que possuem dados negativos e que será necessário corrigir.
No atributo *MaritalStatus* verificamos a existência de dados nulos.

```{r Avaliacao da Tabela CARD}
summary(card)
dim(card)
str(card)
nrow(card[!complete.cases(card),])
table(is.na(card))
unique(card)
table(duplicated(card))
```

Tratamento os dados nulos e errados nas colunas *NumChildren* e *YoungestChild* , pois existem valores negativos. No *MaritalStatus* há dados nulos que devem ser tratados também.

Colocamos a zeros os valores abaixo de zero de *NumChildren* e *YoungestChild*. Também decidimos fazer uma correção quando diz que o número de filhos é zero e depois indica que tem filhos.

```{r Tratamento de dados}

# Podemos verifica que existem alguns registos, caracterizados como outliers, que indicam que não tem filhos mas depois no atributo *NumChildren* existe um valor superior a zero.
plot(card$NumChildren~card$HasChildren)


card$NumChildren[card$NumChildren < 0] <- 0
table(card$NumChildren)
card$YoungestChild[card$YoungestChild < 0] <- 0
table(card$YoungestChild)


## Como existem observacões que indicam ter filhos, mas depois o campo do número de filhos esta a 0, decidimos alterar o atributo "HasChildren" para "N"
card[card$NumChildren == 0 & card$HasChildren == 'Y', .N]
card$HasChildren[card$NumChildren == 0] <- 'N'


## NumChildren>0 e HasChildren
card[card$NumChildren > 0 & card$HasChildren == 'N', .N]
card$HasChildren[card$NumChildren > 0] <- 'Y'

# Verificamos que ficou corrigido, em que agora todos os registos em que *HasChildren* está a N, o *NumChildren* está a zero.
plot(card$NumChildren~card$HasChildren)

## Corrigir os dados de *MaritalStatus* sem valor, para não escolher aleatóriamente o Casado ou Solteiro, decidimos criar o atributo Outro.
table(card$MaritalStatus)

card[MaritalStatus == "", MaritalStatus := "O"]
card$MaritalStatus <- droplevels(card$MaritalStatus)
```

##2. Pre-processamento dos dados

Após o tratamento dos dados é agora necessário a preparação dos mesmos para a aplicação dos algoritmos de classificação.

#### Merge das tabelas dos dados dos clientes *CARD.dat* com os valores de *RFM* obtidos anteriormente
```{r juntar dados dos clientes}

# Juntar o resultado do RFM com a tabela card numa nova tabela
df_card <- merge(card, rfm_result$rfm[,c(1,9)], by.x = 'CardID', by.y = 'customer_id')

# Agora juntar o nosso atributo a prever que se encontra da tabela *CAMPAIGN.dat*
df_card <- merge(df_card, campaign, by = 'CardID')

# Tratamento das datas para data no novo data frame
df_card[, CardStartDate := as.Date(as.character.Date(CardStartDate),"%Y%m%d")]
df_card[, DateOfBirth := as.Date(as.character.Date(DateOfBirth),"%Y%m%d")]

```

Como será mais facil trabalhar os dados com um valor absoluto em vez das datas de idade e data de início de cliente, decidimos trocar estes atributos, usado a variável **analysis_date**, anteriormente definida.
```{r criar as colunas com idade e anos de cliente}
# Criar a idade do cliente em valor absoluto
yr = duration(num = 1, units = "years")
df_card[, age := round(interval(DateOfBirth, analysis_date)/yr,digits = 0)][]

# Anos de clientes, há quanto tempo é cliente
df_card[, clientYears := round(interval(CardStartDate, analysis_date)/yr,digits = 0)][]

# Visualização dos dados
summary(df_card)
```

Agora vamos eliminar dados desnecessários do data frame
```{r retirar id e codigo postal, CardStartDate e DateOfBirth}

# Remoção dos campos de *PostalCode*, CardStartDate e DateOfBirth.
df_card <- df_card[, c(2,3,6,8:15)]

## Mudar o atributo objetivo para o fim da tabela
df_card <- df_card[, c(1:8,10,11,9)]

str(df_card)
```

Para uma mais fácil leitura decidimos criar novos fatores nos atributos *Gender*, *MaritalStatus*, *HasChildren* e *Responded*. 
```{r Conversão de dados e criação de novos fatores}
df_card$Gender <- factor(df_card$Gender, levels = c("F", "M"), labels = c("Feminino", "Masculino"))
df_card$MaritalStatus <- factor(df_card$MaritalStatus, levels = c("M", "S", "O"), labels = c("Casado", "Solteiro", "Outro"))
df_card$HasChildren <- factor(df_card$HasChildren, levels = c("Y", "N"), labels = c("Sim","Nao"))
df_card$Responded <- factor(df_card$Responded, levels = c(TRUE, FALSE), labels = c("Sim","Nao"))

```


#### Visualizacao dos dados para análise

```{r Visualizacao grafica dos dados}
summary(df_card)
str(df_card)

## Verificar a percentagem de clientes que responderam a campanha
barplot(table(df_card$Responded), ylim = c(0,10000), main = "Responded")

prop.table(table(df_card$Responded))*100

```

Podemos verificar que a proporção de *Sim* e *Não* está muito desbalanceada, pelo que irá ser necessário fazer algo para balancear as proporções, visto que alguns algoritmos não vão conseguir prever o *Sim*.

##3. Criacao da função para avaliação de modelos de Data-Mining e data-frame para guardar os resultados.
```{r criacao de funcao para avaliar os modelos e vetor para guardar os resultados, include=TRUE, eval=TRUE}
##Funcao para avaliacao dos modelos e data frame para guardar os dados

allcrosstabmeasures <- function (tst_labels, pred_labels, modelname=""){
  if (length(unique(tst_labels)) == length(unique(pred_labels))) {
    ctmatrix <- CrossTable(tst_labels,pred_labels,prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE, dnn = c("Real","Predicted"))
    accuracy <- sum(diag(ctmatrix$t))/sum(ctmatrix$t)
    recall <- ctmatrix[[1]][1,1]/sum(ctmatrix[[1]][1,]) ##TPR Recall
    precision <- ctmatrix[[1]][1,1]/sum(ctmatrix[[1]][,1])
    fpr <- ctmatrix[[1]][2,1]/sum(ctmatrix[[1]][2,])
    f1 <- 2*precision*recall/(precision+recall)
    pre <- (sum(ctmatrix[[1]][1,])/sum(ctmatrix$t)*sum(ctmatrix[[1]][,1])/sum(ctmatrix$t)) + (sum(ctmatrix[[1]][2,])/sum(ctmatrix$t)*sum(ctmatrix[[1]][,2])/sum(ctmatrix$t))
  kappa <- (accuracy - pre) / (1-pre)
  data.frame(model=modelname,accuracy=round(accuracy,digits = 3),recall=round(recall,digits = 3),precision=round(precision,digits = 3),f1=round(f1,digits = 3), kappa=round(kappa,digits = 3),fpr=round(fpr,digits = 3))
  } else {
    stop("Erro na construcao do modelo")
  }
}


## Declara um data frame para guardar os dados estatisticos
results.df <- data.frame(model = character(),
                         accuracy = double(),
                         recall = double(),
                         precision = double(),
                         f1 = double(),
                         kappa = double(),
                         fpr = double(),
                         stringsAsFactors = FALSE)

```


#### Devido a taxa de *Sim* no atributo *Responded* ser inferior a 20%, foi necessario efetuar um Oversamppling dos dados positivos para equilibrar os mesmos.
```{r Oversampling dos dados, include=TRUE}
## Holdout stratified
   
set.seed(123)

##create of stratified train/test partitions
train.idx <- createDataPartition(df_card$Responded, p = 0.7, list = F)

trainSet <- df_card[ train.idx, ]
tstSet <-   df_card[-train.idx, ]

## Criar o oversampling para resolver o problema dos dados desbalanceados.
oversampling <- trainSet[ which(trainSet$Responded=='Sim'),]
trainSet <- rbind(trainSet,oversampling)
trainSet <- rbind(trainSet,oversampling)
table(trainSet$Responded)
summary(trainSet)

table(trainSet$Responded)
round(prop.table(table(trainSet$Responded))*100, digits = 2)

train_labels <- trainSet$Responded
tst_labels <- tstSet$Responded

round(prop.table(table(train_labels))*100, digits = 2)
round(prop.table(table(tst_labels))*100, digits = 2)

ncols <- dim(trainSet)[2]
ctrl <- trainControl(method = "cv", number = 10)
```


Método C5.0
```{r C5.0, eval=FALSE}
set.seed(123)

modelLookup(model = "C5.0") # Função para verificar as possibilidades do modelo

C5Model <- C5.0(Responded~.,data = trainSet)

summary(C5Model)

C5Predict <- predict(C5Model,newdata = tstSet,type = "class")

results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,C5Predict,"C5.0 Classif."))
results.df
```

Método C5.0 com função treino
```{r C5.0 com funcao treino, eval=FALSE}
####################################################################################################################################################################

## C5.0 com funcao treino


##grade de parametros para otimizar o algoritmo

grid <- expand.grid(winnow = c(TRUE,FALSE), trials = c(1,2,10,15,20), model = "tree")
grid

C5model <- train(Responded~.,data = trainSet,
                 method = 'C5.0',
                 metric = 'Accuracy',
                 trControl = ctrl,
                 tuneGrid = grid)
C5model

trellis.par.set(caretTheme())
plot(C5model)


C5pred <- predict(C5model, tstSet)

table(C5pred)

results.df <- rbind(results.df, allcrosstabmeasures(tst_labels, C5pred, "C5.0 with train caret "))
results.df
```


Método C5.0 with adaptative boosting
```{r C5.0 with adaptative boosting, eval=FALSE}
####################################################################################################################################################################

## C5.0 with adaptative boosting

set.seed(123)

boost100.model <- C5.0(x = trainSet[,c(1:10)],trainSet$Responded, trials = 100)

summary(boost100.model)

boost100.pred <- predict(boost100.model,tstSet)

results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,boost100.pred,"C5.0 with adaptative boosting "))
results.df

####################################################################################################################################################################
```

Método Naive Bayes
```{r Naive Bayes, eval=FALSE}
####################################################################################################################################################################

## Naive Bayes

set.seed(123)

modelLookup(model = "nb") 

Bayesmodel <-train(trainSet[,c(1:10)], y = trainSet$Responded,
                    method = "nb",
                    tuneGrid = data.frame(fL=1,usekernel=FALSE,adjust=1),
                    trControl = ctrl)

Bayespred <- predict(Bayesmodel,tstSet)

results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,Bayespred,"Naive Bayes"))
results.df

####################################################################################################################################################################
```

Método Random Forest
```{r Random Forest, eval=FALSE}


set.seed(123)

modelLookup(model = "rf") 

control <- trainControl(method = "repeatedcv", number = 10, repeats = 3, search  ="grid")

mtry <- round(sqrt(ncol(trainSet)),0)

rfmodel <- train(Responded~.,
                 data=trainSet,
                 method = "rf",
                 tuneGrid = expand.grid(.mtry=1:15),
                 trControl=control,
                 ntree=100)


print(rfmodel)
plot(rfmodel)

varImp(rfmodel)

rfpredict <- predict(rfmodel,newdata = tstSet,type = 'raw')
results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,rfpredict,"Random Forest"))
results.df
```

Método Logistic regression
```{r Logistic Regression, eval=FALSE}

set.seed(123)

modelLookup(model = "glm") 

crtl <- trainControl(method = 'cv', number = 3)

glmodel <- train(Responded~.,
                 data= trainSet,
                 method = 'glm',
                 trControl = crtl)

summary(glmodel)

glmpred <- predict(glmodel, newdata = tstSet)
results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,glmpred,"Logistic regression"))
results.df
```

Método K-Nearest neighbours
```{r K-Nearest neighbours, eval=FALSE}
set.seed(123)

modelLookup(model = "knn") 

knnmodel <- train(Responded~.,
                  data = trainSet,
                  method = 'knn',
                  tuneGrid = expand.grid(k = seq(1,100,2)),
                  metric = 'Accuracy',
                  trControl = crtl)

knnpred <- predict(knnmodel,newdata = tstSet, type = "raw")

results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,knnpred,"K-Nearest neighbours"))
results.df
```

Método Support Vector Machine (SVM) LINEAR
```{r Support Vector Machine (SVM) LINEAR, eval=FALSE}
set.seed(123)

modelLookup(model = "svmLinear") 

svmodel <- train(Responded~.,
                 data = trainSet,
                 method = 'svmLinear',
                 metric = 'Accuracy',
                 maximize = FALSE,
                 tuneLength = 15,
                 trControl = crtl)

svpred <- predict(svmodel,newdata = tstSet)

results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,svpred,"Support Vector Machine (SVM) - Linear"))
results.df
```

Método Support Vector Machine (SVM) RADIAL
```{r Support Vector Machine (SVM) RADIAL, eval=FALSE}
set.seed(123)

modelLookup(model = "svmRadial") 

grid <- expand.grid(sigma = c(.01,.015, 0.2), C = c(0.75, 0.9, 1,1.1,1.25))
svmodelradial <- train(Responded~.,
                 data = trainSet,
                 method = 'svmRadial',
                 PreProc = c("center","scale"),
                 metric = 'Accuracy',
                 maximize = FALSE,
                 tuneGrid = grid,
                 trControl = crtl)

svpredradial <- predict(svmodelradial,newdata = testSet)

results.df <- rbind(results.df,allcrosstabmeasures(test_Labels,svpredradial,"Support Vector Machine (SVM) - Radial"))
results.df
```

## neural network
```{r neural network, eval=FALSE}
set.seed(123)

nnetGrid <- expand.grid(.decay = c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.1), size = (1:10))
nnetGrid <- expand.grid(decay = c(0, 0.01, .1),
                        size = c(1:10))

nnmodel <- train(Responded~.,
                 data = trainSet,
                 method = 'nnet',
                 metric = 'Accuracy',
                 tuneGrid = nnetGrid,
                 trace = FALSE,
                 maxit = 1000,
                 preProc = c("center","scale"),
                 trControl = crtl)

nnpred <- predict(nnmodel,newdata = tstSet)

results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,nnpred,"Neural network"))
results.df
```

##Analise do resultado dos modelos de classificacao.

"True positive" e "true negative" sao as observacões que foram corretamente previstas. a ideia e minimizar os "false positive" e os "false negative", sendo que o mais importante e reduzir o risco de perder negocio, com a identificacao de clientes que nao iriam responder a campanha quando o resultado era positivo.

True Positives (TP) - Estes valores sao valores da classe "Sim" que foram corretamente previstos.

True Negatives (TN) - Sao os valores da classe "Nao" que foram corretamente previstos como "Nao".

Os falsos positivos e os falso negativos sao valores que ocorrem quando o modelo classifica as classes de forma contraria ao atual.

False Positives (FP) - As ocorrências em que se obtem "Sim" na previsao do modelo mas na realidade sao "Nao".

False Negatives (FN) - Ao contrario dos falsos positivos, aqui a previsao originada e o "Nao" mas deveria ter sido "Sim".

Com estes paramtros da matriz de confusao, conseguimos avaliar varios parametros dos modelos, tal como, Accuracy, Precision, Recall e F1 score.


A Accuracy e uma medida de performance do modelo que e um racio entre os valores corretamente previstos tendo em conta o número total de observacões. Esta medida e boa na avaliacao de modelos equilibrados/balanceados, modelos que se obtem o mesmo número de falso positivos e falso negativos. Desta forma e necessario avaliar outras medidas.

Accuracy = TP+TN/TP+FP+FN+TN

Precision - Indica o racio de valores positivos corretamente classificados tendo em conta o total de observacões positivas.

Precision = TP/TP+FP

Recall (Sensitivity) - Indica o racio de observacões corretamente previstas e todas as observacões da classe. Vais indicar quantos dos "Sim" foram corretamente classificados.

Recall = TP/TP+FN

F1 score - Esta medida e uma media pesada entre a Precision e a Recall, tendo em conta ambos os falsos positivos e os falsos negativos. Esta medida podera ser a mais acertada, principalmente no caso de termos classes desbalanceadas. 

F1 Score = 2*(Recall * Precision) / (Recall + Precision)

Resultados obtidos correndo os algoritmos classificacao:

                             model    accuracy  recall    precision   f1    kappa   fpr
                      C5.0 Classif.   0.660     0.392     0.259       0.312 0.099   0.274
             C5.0 with train caret    0.731     0.321     0.317       0.319 0.151   0.169
     C5.0 with adaptative boosting    0.704     0.352     0.291       0.319 0.132   0.210
                   C5.0 with costs    0.731     0.321     0.317       0.319 0.151   0.169
                       Naive Bayes    0.699     0.202     0.215       0.208 0.022   0.180
                     Random Forest    0.762     0.159     0.301       0.208 0.083   0.090
               Logistic regression    0.714     0.171     0.214       0.190 0.019   0.154
                    Neural network    0.654     0.328     0.231       0.271 0.053   0.267


```{r Avaliacao dos modelos}

results.df

barplot(results.df$f1, col = c(1:9), main = "Avaliacao F1", ylim = c(0,0.60))
legend("topright", levels(results.df$model), bty = "n", fill = c(1:length(results.df$model)))

barplot(results.df$precision, col = c(1:9), main = "Avaliacao Precision", ylim = c(0,0.60))
legend("topright", levels(results.df$model), bty = "n", fill = c(1:length(results.df$model)))

barplot(results.df$recall, col = c(1:9), main = "Avaliacao Recall", ylim = c(0,0.60))
legend("topright", levels(results.df$model), bty = "n", fill = c(1:length(results.df$model)))


barplot(results.df$accuracy, col = c(1:9), main = "Avaliacao Accuracy", ylim = c(0,0.90))
legend("topright", levels(results.df$model), bty = "n", fill = c(1:length(results.df$model)))

##Best Recall
results.df[order(results.df$recall, results.df$precision, decreasing = TRUE),]

##Balance between recall and precision - f1
results.df[order(results.df$f1, decreasing= TRUE),]


##Best Accuracy
results.df[order(results.df$accuracy, decreasing= TRUE),]

```

###### SEGUNDA CLASSIFICAcaO ######

## Alterar o RFM para dados categoricos para avaliacao do tipo de cliente
Ao categoriazar os clientes pelo valor de RFM atribuido, podemos tentar prever o tipo dos clientes novos. Os factores da classe a prever foram criados seguindo a seguinte regra:

Com um score de RFM inferior ou igual a 233, consideramos um cliente esporadico.
Com um score de RFM entre 234 e 443, consideramos um cliente regular.
Com um score de RFM superior ou igual a 444, consideramos um cliente frequente.



```{r Criacao de variaveis categoricas a partir dos dados numericos do RFM}

table(df_card$rfm_score)
hist(df_card$rfm_score,breaks = seq(min(df_card$rfm_score), max(df_card$rfm_score), length.out = df_card$rfm_score))

summary(df_card)


df_card$rfm_score_cat <- case_when(df_card$rfm_score <= 233 ~ 'Sporadically',
                  between(df_card$rfm_score, 234, 443) ~ 'Regular',
                  df_card$rfm_score >= 444 ~ 'Frequent'
                  )

df_card$rfm_score_cat <- as.factor(df_card$rfm_score_cat)

summary(df_card)

new_df_card <- df_card[,c(1:7,9,10,12)]
str(new_df_card)
attach(new_df_card)

```

## Declarar um data frame para guardar os dados estatísticos para a segunda classificacao, definida por um clustering manual na classe RFM.

Este clustering manual vai-nos permitir ter um melhor conhecimento dos novos clientes, prevendo a sua possível categoria de cliente.

```{r criacao do novo vetor para guardar os dados da segunda classificacao, , eval=FALSE, include=FALSE}

results.new_df <- data.frame(model = character(),
                         accuracy = double(),
                         recall = double(),
                         precision = double(),
                         f1 = double(),
                         kappa = double(),
                         fpr = double(),
                         stringsAsFactors = FALSE)
```


#### Holdout stratified, neste caso nao consideramos a necessidade de fazer o oversampling pois os valores sao relativamente equilibrados.
```{r Holdout stratified from second classification}


set.seed(123)

table(new_df_card$rfm_score_cat)
round(prop.table(table(new_df_card$rfm_score_cat))*100, digits = 2)


##create of stratified train/test partitions
train.idx <- createDataPartition(new_df_card$rfm_score_cat, p = 0.7, list = F)

trainSet <- new_df_card[ train.idx, ]
tstSet <-   new_df_card[-train.idx, ]

table(trainSet$rfm_score_cat)
round(prop.table(table(trainSet$rfm_score_cat))*100, digits = 2)

train_labels <- trainSet$rfm_score_cat
tst_labels <- tstSet$rfm_score_cat

round(prop.table(table(train_labels))*100, digits = 2)
round(prop.table(table(tst_labels))*100, digits = 2)

ncols <- dim(trainSet)[2]
ctrl <- trainControl(method = "cv", number = 10)
```




```{r C5.0  segunda classificacao, eval=FALSE}
set.seed(123)

modelLookup(model = "C5.0") ## ver o que o model pede

C5Model <- C5.0(rfm_score_cat~.,data = trainSet)

summary(C5Model)

C5Predict <- predict(C5Model,newdata = tstSet,type = "class")

results.new_df <- rbind(results.new_df,allcrosstabmeasures(tst_labels,C5Predict,"C5.0 Classif."))
results.new_df
```

```{r C5.0 with adaptative boosting segunda classificacao, eval=FALSE}
set.seed(123)

boost100.model <- C5.0(rfm_score_cat~.,data = trainSet, trials = 100)

summary(boost100.model)

boost100.pred <- predict(boost100.model,tstSet)

results.new_df <- rbind(results.new_df,allcrosstabmeasures(tst_labels,boost100.pred,"C5.0 with adaptative boosting "))
results.new_df
```


###TODO: Esta a dar erro porque nao consegue prever registo com o atributo frequente.
```{r C5.0 com funcao treino  segunda classificacao, eval=FALSE}
####################################################################################################################################################################

##grade de parametros para otimizar o algoritmo
grid <- expand.grid(winnow = c(TRUE,FALSE), trials = c(1,2,10,15,20), model = "tree")
grid


C5model <- train(rfm_score_cat~.,data = trainSet,
                 method = 'C5.0',
                 metric = 'Accuracy',
                 trControl = ctrl,
                 tuneGrid = grid)
C5model

trellis.par.set(caretTheme())
plot(C5model)


C5pred <- predict(C5model, tstSet)

table(C5pred)

results.new_df <- rbind(results.new_df, allcrosstabmeasures(tst_labels, C5pred, "C5.0 with train caret "))
results.new_df
```


```{r Naive Bayes segunda classificacao, eval=FALSE}
####################################################################################################################################################################

## Naive Bayes

set.seed(123)

Bayesmodel <-train(rfm_score_cat~.,data = trainSet,
                    method = "nb",
                    tuneGrid = data.frame(fL=1,usekernel=FALSE,adjust=1),
                    trControl = ctrl)

Bayespred <- predict(Bayesmodel,tstSet)

results.new_df <- rbind(results.new_df,allcrosstabmeasures(tst_labels,Bayespred,"Naive Bayes"))
results.new_df

####################################################################################################################################################################
```


```{r K-Nearest neighbours segunda classificacao, eval=FALSE}
set.seed(123)

knnmodel <- train(rfm_score_cat~.,
                  data = trainSet,
                  method = 'knn',
                  tuneGrid = expand.grid(k = seq(1,100,2)),
                  metric = 'Accuracy',
                  trControl = crtl)

knnpred <- predict(knnmodel,newdata = tstSet, type = "raw")
table(knnpred)

results.new_df <- rbind(results.new_df,allcrosstabmeasures(tst_labels,knnpred,"K-Nearest neighbours"))
results.new_df
```

###TODO: Esta a dar erro porque nao consegue prever registos com o atributo frequente.
```{r Support Vector Machine (SVM) LINEAR segunda classificacao, eval=FALSE}
set.seed(123)

svmodel <- train(rfm_score_cat~.,
                 data = trainSet,
                 method = 'svmLinear',
                 metric = 'Accuracy',
                 maximize = FALSE,
                 tuneLength = 15,
                 trControl = crtl)

svpred <- predict(svmodel,newdata = tstSet)
table(svpred)

results.new_df <- rbind(results.new_df,allcrosstabmeasures(tst_labels,svpred,"Support Vector Machine (SVM) - Linear"))
results.new_df
```


```{r Support Vector Machine (SVM) RADIAL segunda classificacao, eval=FALSE}
set.seed(123)
grid <- expand.grid(sigma = c(.01,.015, 0.2), C = c(0.75, 0.9, 1,1.1,1.25))
svmodelradial <- train(rfm_score_cat~.,
                 data = trainSet,
                 method = 'svmRadial',
                 PreProc = c("center","scale"),
                 metric = 'Accuracy',
                 maximize = FALSE,
                 tuneGrid = grid,
                 trControl = crtl)

svpredradial <- predict(svmodelradial,newdata = tstSet)
table(svpredradial)

results.new_df <- rbind(results.new_df,allcrosstabmeasures(tst_labels,svpredradial,"Support Vector Machine (SVM) - Radial"))
results.new_df
```


###TODO: Esta a dar erro porque nao consegue prever registos com o atributo frequente.
```{r neural network segunda classificacao, eval=FALSE}
set.seed(123)

nnetGrid <- expand.grid(.decay = c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.1), size = (1:10))
nnetGrid <- expand.grid(decay = c(0, 0.01, .1),
                        size = c(1:10))

nnmodel <- train(rfm_score_cat~.,
                 data = trainSet,
                 method = 'nnet',
                 metric = 'Accuracy',
                 tuneGrid = nnetGrid,
                 trace = FALSE,
                 maxit = 1000,
                 preProc = c("center","scale"),
                 trControl = crtl)

nnpred <- predict(nnmodel,newdata = tstSet)
table(nnpred)

results.new_df <- rbind(results.new_df,allcrosstabmeasures(tst_labels,nnpred,"Neural network"))
results.new_df
```


## Avaliacao dos modelos para previsao do atributo de cliente baseado no RFM.

                                    model    accuracy recall    precision   f1    kappa   fpr
                            C5.0 Classif.    0.376    0.103     0.308       0.154 0.248   0.097
            C5.0 with adaptative boosting    0.376    0.103     0.308       0.154 0.248   0.097
                              Naive Bayes    0.379    0.004     0.174       0.008 0.251   0.010
                     K-Nearest neighbours    0.374    0.044     0.289       0.076 0.223   0.044
    Support Vector Machine (SVM) - Radial    0.364    0.064     0.260       0.103 0.203   0.071



## References
