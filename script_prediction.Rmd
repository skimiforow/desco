---
title: "DESCO - Knowledge Discovery - Forecast responses to future campaigns"
author: "1141074 - SÃ©rgio Silva | 1970400 - Pedro Neves | 1040706 - SÃ©rgio Castro"
date: "11/6/2018"
output:
  pdf_document: default
  editor_options: null
  html_document: default
  chunk_output_type: console
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(error = TRUE)
```

Este documento é focado na parte do processo relativo à classificação de clientes, o objetivo é futuramente conseguirmos prever tendo em conta novos clientes, qual a reposta que se irá ter às campanhas. 

Numa primeira fase vamos esclher que dados dos clientes vamos analisar e como analisar, bem como, algum tipo de tratamento que seja possível efetuar.

Para o calculo da métrica relativa ao RFM será necessário avaliar as tabelas **TRANSACTION.dat** e **TRANSACTION_ITEM.dat**


```{r Limpeza das variáveis de ambiente, include=FALSE}
rm(list = ls())
```


```{r Bibliotecas necessarias, include=FALSE}
library(lattice)
library(ggplot2)
library(caret)
library(C50)
library(data.table)
library(randomForest)
library(rfm)
library(lubridate)
library(gmodels)
library(e1071) ##Nayve Bayes
library(dplyr) ## Para criacao dos valores categoricos a partir dos dados números do RFM

```


## Carregamento das tabelas de **TRANSACTION.dat** e **TRANSACTION_ITEM.dat**

#### Pré-processamento para fazer o merge das duas tabelas, definindo uma chave em ambas as tabelas para efetuar o merge.
```{r Pre-processamento para fazer o merge das duas tabelas}

#Definir a key para efetuar o merge
keycols <- c('Store', 'Date', 'Time', 'TransactionID')

#Tabela TRANSACTION.dat
transactions = fread('DATA-CRM/TRANSACTION.dat')
setkeyv(transactions, keycols)

#Tabela TRANSACTION_ITEM.dat
trans_items = fread('DATA-CRM/TRANSACTION_ITEM.dat')
setkeyv(trans_items, keycols)

```

#### Efetuar 'join' das duas tabelas e remover as observacões contendo datas inválidas
```{r Merge das tabelas}
# Execução do merge
Result <- merge(transactions, trans_items, all = TRUE)

# Tratamento das datas para formato de data
Result[, Date := as.Date(as.character.Date(Date),"%Y%m%d")]

# verificar possíveis erros neste tratamento
Result <- na.omit(Result, cols = "Date")
```


#### Gerar RFM Score com package rfm

O modelo **RFM** (*Recency*, *Frequency*, *Monetary*) é um modelo muito usado para a categorização de clientes, por causa da sua simplicidade e boa capacidade de previsão. 

1. O atributo **Recency** refere-se ao tempo desde a última compra, um valor superior refere-se a uma maior probablidade do cliente efetuar uma compra brevemente.

2. O atributo **Frequency** indica o número de compras efetuadas pelo cliente no período de análise, um valor maior indica uma frequência maior.

3. Por fim, o atributo **Monetary** mostra a quantidade de dinheiro gasta durante o período específico, onde um valor superior indica um cliente que gastou mais dinheiro.

Por defeito, o RFM atribui valores de 1 a 5 e apesar destes valores poderem ser configuráveis, consideramos que são suficientes para avaliar os dados dos clientes. As divisões dos cestos feita com o valor de 5, divide os valores a cada 20% dos dados.
[Ref. @Birant2011]

Calculo do *Recency*, *Frequency*, *Monetary* a partir da tabela de transacões, resultado do *merge* anterior.
```{r RFM algorithm}

# Data definida para a análise, foi defenida a data de 01-01-2015 pois como os dados são de 2014, faria sentido aplicar esta análise nesta altura. 
analysis_date <- as.Date("2015-01-01")


#Aplicação do package *rfm*, com os dados necessário de CardID, Data da última compra e Amount
orders <- Result[, .(CardID, Date, Amount)]
rfm_result <- rfm_table_order(data = orders, customer_id = CardID, order_date = Date, revenue = Amount, analysis_date = analysis_date, recency_bins = 5, frequency_bins = 5, monetary_bins = 5)
```

Análise dos dados obtidos na aplicação do algotirtmo de **RFM** do package *rfm*
```{r RFM algorithm analysis, include=FALSE}

# Verificação visual dos dados
summary(rfm_result)
str(rfm_result)

# Examinar a distribuição dos resultados de monetary para diferentes combinações de resultados de frequency e recency.
rfm_bar_chart(rfm_result)

# Distribuição dos Histogramas para as 3 medidas de Recency, Frequency e Monetary
rfm_histograms(rfm_result)

## Correlacionar a data da última compra com a frequência de compra
rfm_rm_plot(rfm_result, point_color = "blue", xaxis_title = "Monetary",
yaxis_title = "Recency", plot_title = "Recency vs Monetary")

## Correlacionar a Frequência com o valor gasto
rfm_fm_plot(rfm_result, point_color = "blue", xaxis_title = "Monetary",
yaxis_title = "Frequency", plot_title = "Frequency vs Monetary")

## Correlacionar a data da última compra com o valor gasto
rfm_rf_plot(rfm_result, point_color = "blue", xaxis_title = "Frequency",
yaxis_title = "Recency", plot_title = "Recency vs Frequency")

## Heat Map de relacionamento das três variáveis
rfm_heatmap(rfm_result, plot_title = "RFM Heat Map", plot_title_justify = 0.5,
xaxis_title = "Frequency", yaxis_title = "Recency",
legend_title = "Mean Monetary Value", brewer_n = 5,
brewer_name = "PuBu")

```

Caso fosse necessário o calculo dos atributos do algoritmo RFM, poderíamos usar as seguintes formulas. As mesmas nao foram usadas pois usamos o package RFM que nos efetua estes calculo automaticamente. [Ref. @Fan2016]

Calculo "Manual" das três dimensões do RFM
```{r include=TRUE, eval=FALSE}
## Frequency
rfm_frequency <- Result[, .N, by = CardID]

## Monetary
rfm_monetary <- Result[ , .(Total = sum(Amount)), by = CardID]

## Recency
rfm_recency <- Result[, .(LatestOrder = max(Date)), by = CardID][, .(Recency = analysis_date - LatestOrder), by = CardID]
```


##1. Exploracao e preparacao dos dados

Nesta fase e após termos os valores de *RFM*, vamos iniciar o processo de análise e preparação dos dados para a fase de classificação.

#### Tabela CAMPAIGN.DAT
Após o carregamento da tabela *CAMPAIGN.dat*
```{r CAMPAIGN.dat}
campaign <- read.table("DATA-CRM/CAMPAIGN.dat", header = TRUE, sep = ",", dec = ",")
```

É necessário efetuar a verificacao dos dados da tabela *CAMPAIGN.dat*, tal como o número de colunas e linhas, bem como se os dados foram corretamente carregados.
```{r include=FALSE}
summary(campaign)
dim(campaign)
str(campaign)
```

Verificar se a tabela possui dados nulos, o que não acontece.
Esta tabela é muito simples e não houve dados a corrigir.
```{r include=FALSE}
table(is.na(campaign))
unique(campaign)
table(duplicated(campaign))

```

#### Tabela CARD.dat
Carregamento da tabela *CARD.dat* bem como a sua transformação para *Data Table* para facilitar o tratamento posteriormente.
```{r CARD.dat}
card <- read.table("DATA-CRM/CARD.dat", header = TRUE, sep = ",", dec = ",")
setDT(card)
```

Verificacao dos dados da tabela card, tal como o número de colunas e linhas, bem como se os dados foram corretamente carregados.
Podemos verificar alguns dados como *NumChildren* e *YoungestChild* que possuem dados negativos e que será necessário corrigir.
No atributo *MaritalStatus* verificamos a existência de dados nulos.

```{r Avaliacao da Tabela CARD}
summary(card)
dim(card)
str(card)
nrow(card[!complete.cases(card),])
table(is.na(card))
unique(card)
table(duplicated(card))
```

Tratamento os dados nulos e errados nas colunas *NumChildren* e *YoungestChild* , pois existem valores negativos. No *MaritalStatus* há dados nulos que devem ser tratados também.

Colocamos a zeros os valores abaixo de zero de *NumChildren* e *YoungestChild*. Também decidimos fazer uma correção quando diz que o número de filhos é zero e depois indica que tem filhos.

```{r Tratamento de dados}

# Podemos verifica que existem alguns registos, caracterizados como outliers, que indicam que não tem filhos mas depois no atributo *NumChildren* existe um valor superior a zero.
plot(card$NumChildren~card$HasChildren)


card$NumChildren[card$NumChildren < 0] <- 0
table(card$NumChildren)
card$YoungestChild[card$YoungestChild < 0] <- 0
table(card$YoungestChild)


## Como existem observacões que indicam ter filhos, mas depois o campo do número de filhos esta a 0, decidimos alterar o atributo "HasChildren" para "N"
card[card$NumChildren == 0 & card$HasChildren == 'Y', .N]
card$HasChildren[card$NumChildren == 0] <- 'N'


## NumChildren>0 e HasChildren
card[card$NumChildren > 0 & card$HasChildren == 'N', .N]
card$HasChildren[card$NumChildren > 0] <- 'Y'

# Verificamos que ficou corrigido, em que agora todos os registos em que *HasChildren* está a N, o *NumChildren* está a zero.
plot(card$NumChildren~card$HasChildren)

## Corrigir os dados de *MaritalStatus* sem valor, para não escolher aleatóriamente o Casado ou Solteiro, decidimos criar o atributo Outro.
table(card$MaritalStatus)

card[MaritalStatus == "", MaritalStatus := "O"]
card$MaritalStatus <- droplevels(card$MaritalStatus)
```

##2. Pre-processamento dos dados

Após o tratamento dos dados é agora necessário a preparação dos mesmos para a aplicação dos algoritmos de classificação.

#### Merge das tabelas dos dados dos clientes *CARD.dat* com os valores de *RFM* obtidos anteriormente
```{r juntar dados dos clientes}

# Juntar o resultado do RFM com a tabela card numa nova tabela
df_card <- merge(card, rfm_result$rfm[,c(1,9)], by.x = 'CardID', by.y = 'customer_id')

# Agora juntar o nosso atributo a prever que se encontra da tabela *CAMPAIGN.dat*
df_card <- merge(df_card, campaign, by = 'CardID')

# Tratamento das datas para data no novo data frame
df_card[, CardStartDate := as.Date(as.character.Date(CardStartDate),"%Y%m%d")]
df_card[, DateOfBirth := as.Date(as.character.Date(DateOfBirth),"%Y%m%d")]

```

Como será mais facil trabalhar os dados com um valor absoluto em vez das datas de idade e data de início de cliente, decidimos trocar estes atributos, usado a variável **analysis_date**, anteriormente definida.
```{r criar as colunas com idade e anos de cliente}
# Criar a idade do cliente em valor absoluto
yr = duration(num = 1, units = "years")
df_card[, age := round(interval(DateOfBirth, analysis_date)/yr,digits = 0)][]

# Anos de clientes, há quanto tempo é cliente
df_card[, clientYears := round(interval(CardStartDate, analysis_date)/yr,digits = 0)][]

# Visualização dos dados
summary(df_card)
```

Agora vamos eliminar dados desnecessários do data frame
```{r retirar id e codigo postal, CardStartDate e DateOfBirth}

# Remoção dos campos de *PostalCode*, CardStartDate e DateOfBirth.
df_card <- df_card[, c(2,3,6,8:15)]

## Mudar o atributo objetivo para o fim da tabela
df_card <- df_card[, c(1:8,10,11,9)]

str(df_card)
```

Para uma mais fácil leitura decidimos criar novos fatores nos atributos *Gender*, *MaritalStatus*, *HasChildren* e *Responded*. 
```{r Conversão de dados e criação de novos fatores}
df_card$Gender <- factor(df_card$Gender, levels = c("F", "M"), labels = c("Feminino", "Masculino"))
df_card$MaritalStatus <- factor(df_card$MaritalStatus, levels = c("M", "S", "O"), labels = c("Casado", "Solteiro", "Outro"))
df_card$HasChildren <- factor(df_card$HasChildren, levels = c("Y", "N"), labels = c("Sim","Nao"))
df_card$Responded <- factor(df_card$Responded, levels = c(TRUE, FALSE), labels = c("Sim","Nao"))

```


### Visualizacao dos dados para análise
```{r Visualizacao grafica dos dados}
summary(df_card)
str(df_card)

## Verificar a percentagem de clientes que responderam a campanha
barplot(table(df_card$Responded), ylim = c(0,10000), main = "Responded")

prop.table(table(df_card$Responded))*100

```

Podemos verificar que a proporção de *Sim* e *Não* está muito desbalanceada, pelo que irá ser necessário fazer algo para balancear as proporções, visto que alguns algoritmos não vão conseguir prever o *Sim*.

##3. Criacao da função para avaliação de modelos de Data-Mining e data-frame para guardar os resultados.
```{r criacao de funcao para avaliar os modelos e vetor para guardar os resultados, include=TRUE, eval=TRUE}
##Funcao para avaliacao dos modelos e data frame para guardar os dados

allcrosstabmeasures <- function (tst_labels, pred_labels, modelname=""){
  if (length(unique(tst_labels)) == length(unique(pred_labels))) {
    ctmatrix <- CrossTable(tst_labels,pred_labels,prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE, dnn = c("Real","Predicted"))
    accuracy <- sum(diag(ctmatrix$t))/sum(ctmatrix$t)
    recall <- ctmatrix[[1]][1,1]/sum(ctmatrix[[1]][1,]) ##TPR Recall
    precision <- ctmatrix[[1]][1,1]/sum(ctmatrix[[1]][,1])
    fpr <- ctmatrix[[1]][2,1]/sum(ctmatrix[[1]][2,])
    f1 <- 2*precision*recall/(precision+recall)
    pre <- (sum(ctmatrix[[1]][1,])/sum(ctmatrix$t)*sum(ctmatrix[[1]][,1])/sum(ctmatrix$t)) + (sum(ctmatrix[[1]][2,])/sum(ctmatrix$t)*sum(ctmatrix[[1]][,2])/sum(ctmatrix$t))
  kappa <- (accuracy - pre) / (1-pre)
  data.frame(model=modelname,accuracy=round(accuracy,digits = 3),recall=round(recall,digits = 3),precision=round(precision,digits = 3),f1=round(f1,digits = 3), kappa=round(kappa,digits = 3),fpr=round(fpr,digits = 3))
  } else {
    stop("Erro na construcao do modelo")
  }
}


## Declara um data frame para guardar os dados estatisticos
results.df <- data.frame(model = character(),
                         accuracy = double(),
                         recall = double(),
                         precision = double(),
                         f1 = double(),
                         kappa = double(),
                         fpr = double(),
                         stringsAsFactors = FALSE)

```


#### Devido a taxa de *Sim* no atributo *Responded* ser inferior a 20%, foi necessario efetuar um Oversamppling dos dados positivos para equilibrar os mesmos.

## Holdout stratified
```{r Oversampling dos dados, include=TRUE}
## Holdout stratified
   
set.seed(123)


##create of stratified train/test partitions
train.idx <- createDataPartition(df_card$Responded, p = 0.7, list = F)

trainSet <- df_card[ train.idx, ]
tstSet <-   df_card[-train.idx, ]
attach(trainSet)

## Criar o oversampling para resolver o problema dos dados desbalanceados.
oversampling <- trainSet[ which(trainSet$Responded=='Sim'),]
trainSet <- rbind(trainSet,oversampling)
trainSet <- rbind(trainSet,oversampling)
table(trainSet$Responded)
summary(trainSet)

table(trainSet$Responded)
round(prop.table(table(trainSet$Responded))*100, digits = 2)

train_labels <- trainSet$Responded
tst_labels <- tstSet$Responded

round(prop.table(table(train_labels))*100, digits = 2)
round(prop.table(table(tst_labels))*100, digits = 2)

ncols <- dim(trainSet)[2]
ctrl <- trainControl(method = "cv", number = 10)
```


## Método C5.0
```{r C5.0, eval=FALSE}
set.seed(123)

modelLookup(model = "C5.0") # Função para verificar as possibilidades do modelo

C5Model <- C5.0(Responded~.,data = trainSet)

summary(C5Model)

C5Predict <- predict(C5Model,newdata = tstSet,type = "class")

results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,C5Predict,"C5.0 Classif."))
results.df
```

Alguns dos dados que obtemos na execução dos algotirmos, tais como a àrvore de classificação, bem como, os atributos por ordem de utilização:

      	Attribute usage:
      
      	100.00%	clientYears
      	 93.74%	rfm_score
      	 87.66%	City
      	 58.82%	YoungestChild
      	 49.04%	MaritalStatus
      	 48.63%	age
      	 47.55%	NumChildren
      	 19.44%	Gender
      	 14.50%	HasChildren
      	  5.09%	Region

A matriz de confusão que nos permite ter acesso às medidas de avaliação dos modelos criados:

                 | Predicted 
            Real |       Sim |       Nao | Row Total | 
    -------------|-----------|-----------|-----------|
             Sim |       282 |       437 |       719 | 
                 |     0.077 |     0.119 |           | 
    -------------|-----------|-----------|-----------|
             Nao |       806 |      2134 |      2940 | 
                 |     0.220 |     0.583 |           | 
    -------------|-----------|-----------|-----------|
    Column Total |      1088 |      2571 |      3659 | 
    -------------|-----------|-----------|-----------|


## Método C5.0 com função treino
```{r C5.0 com funcao treino, eval=FALSE}

## C5.0 com funcao treino
set.seed(123)


##grade de parametros para otimizar o algoritmo
grid <- expand.grid(winnow = c(TRUE,FALSE), trials = c(1,2,10,15,20), model = "tree")
grid

C5model <- train(Responded~.,data = trainSet,
                 method = 'C5.0',
                 metric = 'Accuracy',
                 trControl = ctrl,
                 tuneGrid = grid)
C5model
```


```{r C5.0 com funcao treino Winnow}

trellis.par.set(caretTheme())
plot(C5model)
```

Método C5.0 com função treino execução
```{r C5.0 com funcao treino execução do modelos, eval=FALSE}

C5pred <- predict(C5model, tstSet)

table(C5pred)

results.df <- rbind(results.df, allcrosstabmeasures(tst_labels, C5pred, "C5.0 with train caret "))
results.df
```


Matriz de confusão do método C5.0 com funcao treino:

                 | Predicted 
            Real |       Sim |       Nao | Row Total | 
    -------------|-----------|-----------|-----------|
             Sim |       231 |       488 |       719 | 
                 |     0.063 |     0.133 |           | 
    -------------|-----------|-----------|-----------|
             Nao |       498 |      2442 |      2940 | 
                 |     0.136 |     0.667 |           | 
    -------------|-----------|-----------|-----------|
    Column Total |       729 |      2930 |      3659 | 
    -------------|-----------|-----------|-----------|

## Método C5.0 with adaptative boosting
```{r C5.0 with adaptative boosting, eval=FALSE}

## C5.0 with adaptative boosting

set.seed(123)

boost100.model <- C5.0(x = trainSet[,c(1:10)],trainSet$Responded, trials = 100)

summary(boost100.model)

boost100.pred <- predict(boost100.model,tstSet)

results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,boost100.pred,"C5.0 with adaptative boosting "))
results.df

```


Matriz de confusão do método C5.0 com adaptative boosting:

                 | Predicted 
            Real |       Sim |       Nao | Row Total | 
    -------------|-----------|-----------|-----------|
             Sim |       253 |       466 |       719 | 
                 |     0.069 |     0.127 |           | 
    -------------|-----------|-----------|-----------|
             Nao |       616 |      2324 |      2940 | 
                 |     0.168 |     0.635 |           | 
    -------------|-----------|-----------|-----------|
    Column Total |       869 |      2790 |      3659 | 
    -------------|-----------|-----------|-----------|



Com a matrix de custos a ideia é tentar melhorar as previsões atribuindo custos a previsões menos desejadas.
A ideia é atribuir um custo superior quando ele considera um cliente que respondeu a uma campanha na realidade como não ter respondido.
```{r C5.0 com matriz de custos, eval=FALSE}

set.seed(123)


cost.matrix <- matrix(c(
  0, 1,
  4, 0
),2,2, byrow=TRUE)

rownames(cost.matrix) <- colnames(cost.matrix) <- levels(trainSet$Responded)

cost.matrix

fitControl <- trainControl(method="repeatedcv", number=10, repeats=5)


grid <- expand.grid(winnow = c(TRUE,FALSE), trials = c(1,2,10,15,20), model = "tree",cost = cost.matrix)
grid

C5modelCosts <- train(Responded~.,data = trainSet,
                 method = "C5.0Cost",
                 metric = "Accuracy",
                 trControl = fitControl,
                 tuneGrid = grid)

C5modelCosts

C5predCosts <- predict(C5modelCosts,tstSet)

results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,C5predCosts,"C5.0 with costs "))
results.df

```


Matriz de confusão do método C5.0 com matriz de custos:

                 | Predicted 
            Real |       Sim |       Nao | Row Total | 
    -------------|-----------|-----------|-----------|
             Sim |       276 |       443 |       719 | 
                 |     0.075 |     0.121 |           | 
    -------------|-----------|-----------|-----------|
             Nao |       677 |      2263 |      2940 | 
                 |     0.185 |     0.618 |           | 
    -------------|-----------|-----------|-----------|
    Column Total |       953 |      2706 |      3659 | 
    -------------|-----------|-----------|-----------|


## Método Naive Bayes
```{r Naive Bayes, eval=FALSE}
####################################################################################################################################################################

## Naive Bayes

set.seed(123)

modelLookup(model = "nb") 

Bayesmodel <-train(trainSet[,c(1:10)], y = trainSet$Responded,
                    method = "nb",
                    tuneGrid = data.frame(fL=1,usekernel=FALSE,adjust=1),
                    trControl = ctrl)

Bayespred <- predict(Bayesmodel,tstSet)

results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,Bayespred,"Naive Bayes"))
results.df

####################################################################################################################################################################
```

Matriz de confusão do método Naive Bayes:

                 | Predicted 
            Real |       Sim |       Nao | Row Total | 
    -------------|-----------|-----------|-----------|
             Sim |       145 |       574 |       719 | 
                 |     0.040 |     0.157 |           | 
    -------------|-----------|-----------|-----------|
             Nao |       529 |      2411 |      2940 | 
                 |     0.145 |     0.659 |           | 
    -------------|-----------|-----------|-----------|
    Column Total |       674 |      2985 |      3659 | 
    -------------|-----------|-----------|-----------|


## Método Random Forest
```{r Random Forest, eval=FALSE}


set.seed(123)

modelLookup(model = "rf") 

control <- trainControl(method = "repeatedcv", number = 10, repeats = 3, search  ="grid")

mtry <- round(sqrt(ncol(trainSet)),0)

rfmodel <- train(Responded~.,
                 data=trainSet,
                 method = "rf",
                 tuneGrid = expand.grid(.mtry=1:15),
                 trControl=control,
                 ntree=100)
```

```{r Random Forest plot}

print(rfmodel)
plot(rfmodel)

varImp(rfmodel)
```

Método Random Forest execução do modelo
```{r Random Forest avaliação, eval=FALSE}

rfpredict <- predict(rfmodel,newdata = tstSet,type = 'raw')
results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,rfpredict,"Random Forest"))
results.df
```

Matriz de confusão do método Random Forest:

                 | Predicted 
            Real |       Sim |       Nao | Row Total | 
    -------------|-----------|-----------|-----------|
             Sim |       114 |       605 |       719 | 
                 |     0.031 |     0.165 |           | 
    -------------|-----------|-----------|-----------|
             Nao |       265 |      2675 |      2940 | 
                 |     0.072 |     0.731 |           | 
    -------------|-----------|-----------|-----------|
    Column Total |       379 |      3280 |      3659 | 
    -------------|-----------|-----------|-----------|


## Método Logistic regression
```{r Logistic Regression, eval=FALSE}

set.seed(123)

modelLookup(model = "glm") 

crtl <- trainControl(method = 'cv', number = 3)

glmodel <- train(Responded~.,
                 data= trainSet,
                 method = 'glm',
                 trControl = crtl)

summary(glmodel)

glmpred <- predict(glmodel, newdata = tstSet)
results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,glmpred,"Logistic regression"))
results.df
```


Matriz de confusão do método Logistic regression:

                 | Predicted 
            Real |       Sim |       Nao | Row Total | 
    -------------|-----------|-----------|-----------|
             Sim |       123 |       596 |       719 | 
                 |     0.034 |     0.163 |           | 
    -------------|-----------|-----------|-----------|
             Nao |       452 |      2488 |      2940 | 
                 |     0.124 |     0.680 |           | 
    -------------|-----------|-----------|-----------|
    Column Total |       575 |      3084 |      3659 | 
    -------------|-----------|-----------|-----------|

## Método K-Nearest neighbours
```{r K-Nearest neighbours, eval=FALSE}
set.seed(123)

modelLookup(model = "knn") 

knnmodel <- train(Responded~.,
                  data = trainSet,
                  method = 'knn',
                  tuneGrid = expand.grid(k = seq(1,100,2)),
                  metric = 'Accuracy',
                  trControl = crtl)

knnpred <- predict(knnmodel,newdata = tstSet, type = "raw")

results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,knnpred,"K-Nearest neighbours"))
results.df
```

Matriz de confusão do método K-Nearest neighbours:

                 | Predicted 
            Real |       Sim |       Nao | Row Total | 
    -------------|-----------|-----------|-----------|
             Sim |       202 |       517 |       719 | 
                 |     0.055 |     0.141 |           | 
    -------------|-----------|-----------|-----------|
             Nao |       690 |      2250 |      2940 | 
                 |     0.189 |     0.615 |           | 
    -------------|-----------|-----------|-----------|
    Column Total |       892 |      2767 |      3659 | 
    -------------|-----------|-----------|-----------|

## Método Support Vector Machine (SVM) LINEAR
```{r Support Vector Machine (SVM) LINEAR, eval=FALSE}
set.seed(123)

modelLookup(model = "svmLinear2") 

svmodel <- train(Responded~.,
                 data = trainSet,
                 method = 'svmLinear2',
                 metric = 'Accuracy',
                 maximize = FALSE,
                 tuneLength = 15,
                 trControl = crtl)

svpred <- predict(svmodel,newdata = tstSet)

results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,svpred,"Support Vector Machine (SVM) - Linear"))
results.df
```

## Método Support Vector Machine (SVM) RADIAL
```{r Support Vector Machine (SVM) RADIAL, eval=FALSE}
set.seed(123)

modelLookup(model = "svmRadial") 

grid <- expand.grid(sigma = c(.01,.015, 0.2), C = c(0.75, 0.9, 1,1.1,1.25))
svmodelradial <- train(Responded~.,
                 data = trainSet,
                 method = 'svmRadial',
                 PreProc = c("center","scale"),
                 metric = 'Accuracy',
                 maximize = FALSE,
                 tuneGrid = grid,
                 trControl = crtl)

svpredradial <- predict(svmodelradial,newdata = testSet)

results.df <- rbind(results.df,allcrosstabmeasures(test_Labels,svpredradial,"Support Vector Machine (SVM) - Radial"))
results.df
```

## Método neural network
```{r neural network, eval=FALSE}
set.seed(123)

nnetGrid <- expand.grid(.decay = c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.1), size = (1:10))
nnetGrid <- expand.grid(decay = c(0, 0.01, .1),
                        size = c(1:10))

nnmodel <- train(Responded~.,
                 data = trainSet,
                 method = 'nnet',
                 metric = 'Accuracy',
                 tuneGrid = nnetGrid,
                 trace = FALSE,
                 maxit = 1000,
                 preProc = c("center","scale"),
                 trControl = crtl)

nnpred <- predict(nnmodel,newdata = tstSet)

results.df <- rbind(results.df,allcrosstabmeasures(tst_labels,nnpred,"Neural network"))
results.df
```

##Análise do resultado dos modelos de classificação.

**True positive** e **true negative** são as observacões que foram corretamente previstas. a ideia aqui é minimizar os "false positive" e os "false negative", sendo que o mais importante é reduzir o risco de perder negócio com a classificação errada, com a identificação de clientes que não iriam responder à campanha quando o resultado era na realidade positivo.

**True Positives** (TP) - Estes valores são valores da classe "Sim" que foram corretamente previstos.

**True Negatives** (TN) - Sao os valores da classe "Não" que foram corretamente previstos.

Os falsos positivos e os falso negativos são valores que ocorrem quando o modelo classifica as classes erradamente e de forma contrária ao real

**False Positives** (FP) - As ocorrências em que se obtem "Sim" na previsao do modelo mas na realidade sao "Não".

**False Negatives** (FN) - Ao contrario dos falsos positivos, aqui a previsao originada e o "Não" mas deveria ter sido "Sim".

Com estes parâmetros da matriz de confusão, conseguimos avaliar vários parâmetros dos modelos, tal como, *Accuracy*, *Precision*, *Recall* e *F1 score*.


A *Accuracy* é uma medida de performance do modelo que e um racio entre os valores corretamente previstos tendo em conta o número total de observacões. Esta medida é boa na avaliação de modelos equilibrados/balanceados, modelos que se obtem o mesmo número de falso positivos e falso negativos. Desta forma e como não é o caso, é necessario avaliar com outras medidas.

*Accuracy = TP+TN/TP+FP+FN+TN*

*Precision* - Indica o racio de valores positivos corretamente classificados tendo em conta o total de observacões positivas.

*Precision = TP/TP+FP*

*Recall* (Sensitivity) - Indica o racio de observacões corretamente previstas e todas as observacões da classe. Vai indicar quantos dos "Sim" foram corretamente classificados.

*Recall = TP/TP+FN*

*F1 score* - Esta medida e uma media pesada entre a Precision e a Recall, tendo em conta ambos os falsos positivos e os falsos negativos. Esta medida podera ser a mais acertada, principalmente no caso de termos classes desbalanceadas. 

*F1 Score = 2 x (Recall x Precision) / (Recall + Precision)*

Resultados obtidos correndo os algoritmos classificação:

                             model    accuracy  recall    precision   f1    kappa   fpr
                      C5.0 Classif.   0.660     0.392     0.259       0.312 0.099   0.274
             C5.0 with train caret    0.731     0.321     0.317       0.319 0.151   0.169
     C5.0 with adaptative boosting    0.704     0.352     0.291       0.319 0.132   0.210
                   C5.0 with costs    0.694     0.384     0.290       0.330 0.137   0.230
                       Naive Bayes    0.699     0.202     0.215       0.208 0.022   0.180
                     Random Forest    0.762     0.159     0.301       0.208 0.083   0.090
               Logistic regression    0.714     0.171     0.214       0.190 0.019   0.154
              K-Nearest neighbours    0.670     0.281     0.226       0.251 0.042   0.235
                    Neural network    0.654     0.328     0.231       0.271 0.053   0.267

##Avaliação dos modelos

Devido ao grande desbalanceamento dos dados podemos observar que os valor obtidos de nas medidas de análise são muito baixos.

. A medida de *accuracy* encontra-se entre os 65% e 76%
. A medida de *recall* encontra-se entre os 16% e 39%
. A medida de *precision* encontra-se entre os 22% e 32%
. A medida de *f1* encontra-se entre os 19% e 33%

Nesta avaliação os métodos de classificação o método que apresentou melhores resultados foi o:

                             model    accuracy  recall    precision   f1    kappa   fpr
                   C5.0 with costs    0.694     0.384     0.290       0.330 0.137   0.230
                   
Apesar de não ser o método que apresentou a melhor *accuracy*, foi o que mostrou melhores resultados no *score f1*, que será a variável mais interessante no caso dos dados aqui analisados.


```{r Avaliacao dos modelos}

results.df

barplot(results.df$f1, col = c(1:9), main = "Avaliacao F1", ylim = c(0,0.60))
legend("topright", levels(results.df$model), bty = "n", fill = c(1:length(results.df$model)))

barplot(results.df$precision, col = c(1:9), main = "Avaliacao Precision", ylim = c(0,0.60))
legend("topright", levels(results.df$model), bty = "n", fill = c(1:length(results.df$model)))

barplot(results.df$recall, col = c(1:9), main = "Avaliacao Recall", ylim = c(0,0.60))
legend("topright", levels(results.df$model), bty = "n", fill = c(1:length(results.df$model)))


barplot(results.df$accuracy, col = c(1:9), main = "Avaliacao Accuracy", ylim = c(0,0.90))
legend("topright", levels(results.df$model), bty = "n", fill = c(1:length(results.df$model)))

##Best Recall
results.df[order(results.df$recall, results.df$precision, decreasing = TRUE),]

##Balance between recall and precision - f1
results.df[order(results.df$f1, decreasing= TRUE),]


##Best Accuracy
results.df[order(results.df$accuracy, decreasing= TRUE),]

```

###### SEGUNDA CLASSIFICAcaO ######

## Para uma segunda classificação dos clientes, forma usados os dados do *score RFM*, em que estes dados númericos forma convertidos para fatores de acordo com uma regra definida abaixo.

Ao categoriazar os clientes pelo valor de RFM atribuido, podemos tentar prever o tipo dos clientes novos. 

Os factores da classe a prever foram criados seguindo a seguinte regra:

Com um score de *RFM* inferior ou igual a 233, consideramos um cliente **esporádico.**
Com um score de *RFM* entre 234 e 443, consideramos um cliente **regular.**
Com um score de *RFM* superior ou igual a 444, consideramos um cliente **frequente.**



```{r Criacao de variaveis categoricas a partir dos dados numericos do RFM}

table(df_card$rfm_score)
hist(df_card$rfm_score,breaks = seq(min(df_card$rfm_score), max(df_card$rfm_score), length.out = df_card$rfm_score))

summary(df_card)


df_card$rfm_score_cat <- case_when(df_card$rfm_score <= 233 ~ 'Sporadically',
                  between(df_card$rfm_score, 234, 443) ~ 'Regular',
                  df_card$rfm_score >= 444 ~ 'Frequent'
                  )

df_card$rfm_score_cat <- as.factor(df_card$rfm_score_cat)

summary(df_card)

new_df_card <- df_card[,c(1:7,9,10,12)]
str(new_df_card)
attach(new_df_card)

```

## Declarar um data frame para guardar os dados estatísticos para a segunda classificacao, definida por um clustering manual na classe RFM.

Este clustering manual vai-nos permitir ter um melhor conhecimento dos novos clientes, prevendo a sua possível categoria de cliente.

```{r criacao do novo vetor para guardar os dados da segunda classificacao, , eval=FALSE, include=FALSE}

results.new_df <- data.frame(model = character(),
                         accuracy = double(),
                         recall = double(),
                         precision = double(),
                         f1 = double(),
                         kappa = double(),
                         fpr = double(),
                         stringsAsFactors = FALSE)
```


## Holdout stratified, neste caso nao consideramos a necessidade de fazer o oversampling pois os valores sao relativamente equilibrados.
```{r Holdout stratified from second classification}


set.seed(123)

table(new_df_card$rfm_score_cat)
round(prop.table(table(new_df_card$rfm_score_cat))*100, digits = 2)


##create of stratified train/test partitions
train.idx <- createDataPartition(new_df_card$rfm_score_cat, p = 0.7, list = F)

trainSet <- new_df_card[ train.idx, ]
tstSet <-   new_df_card[-train.idx, ]

table(trainSet$rfm_score_cat)
round(prop.table(table(trainSet$rfm_score_cat))*100, digits = 2)

train_labels <- trainSet$rfm_score_cat
tst_labels <- tstSet$rfm_score_cat

round(prop.table(table(train_labels))*100, digits = 2)
round(prop.table(table(tst_labels))*100, digits = 2)

ncols <- dim(trainSet)[2]
ctrl <- trainControl(method = "cv", number = 10)
```



Método de classificação C5.0
```{r C5.0  segunda classificacao, eval=FALSE}
set.seed(123)

modelLookup(model = "C5.0") ## ver o que o model pede

C5Model <- C5.0(rfm_score_cat~.,data = trainSet)

summary(C5Model)

C5Predict <- predict(C5Model,newdata = tstSet,type = "class")

results.new_df <- rbind(results.new_df,allcrosstabmeasures(tst_labels,C5Predict,"C5.0 Classif."))
results.new_df
```

Método de classificação C5.0 com adpatative boosting
```{r C5.0 with adaptative boosting segunda classificacao, eval=FALSE}
set.seed(123)

boost100.model <- C5.0(rfm_score_cat~.,data = trainSet, trials = 100)

summary(boost100.model)

boost100.pred <- predict(boost100.model,tstSet)

results.new_df <- rbind(results.new_df,allcrosstabmeasures(tst_labels,boost100.pred,"C5.0 with adaptative boosting "))
results.new_df
```


Método de classificação Naive Bayes.
```{r Naive Bayes segunda classificacao, eval=FALSE}
####################################################################################################################################################################

## Naive Bayes

set.seed(123)

Bayesmodel <-train(rfm_score_cat~.,data = trainSet,
                    method = "nb",
                    tuneGrid = data.frame(fL=1,usekernel=FALSE,adjust=1),
                    trControl = ctrl)

Bayespred <- predict(Bayesmodel,tstSet)

results.new_df <- rbind(results.new_df,allcrosstabmeasures(tst_labels,Bayespred,"Naive Bayes"))
results.new_df

####################################################################################################################################################################
```

Método de classificação K-Nearest neighbours.
```{r K-Nearest neighbours segunda classificacao, eval=FALSE}
set.seed(123)

knnmodel <- train(rfm_score_cat~.,
                  data = trainSet,
                  method = 'knn',
                  tuneGrid = expand.grid(k = seq(1,100,2)),
                  metric = 'Accuracy',
                  trControl = crtl)

knnpred <- predict(knnmodel,newdata = tstSet, type = "raw")
table(knnpred)

results.new_df <- rbind(results.new_df,allcrosstabmeasures(tst_labels,knnpred,"K-Nearest neighbours"))
results.new_df
```


Método de classificação Suport Vector Machine com o method Radial.
```{r Support Vector Machine (SVM) RADIAL segunda classificacao, eval=FALSE}
set.seed(123)
grid <- expand.grid(sigma = c(.01,.015, 0.2), C = c(0.75, 0.9, 1,1.1,1.25))
svmodelradial <- train(rfm_score_cat~.,
                 data = trainSet,
                 method = 'svmRadial',
                 PreProc = c("center","scale"),
                 metric = 'Accuracy',
                 maximize = FALSE,
                 tuneGrid = grid,
                 trControl = crtl)

svpredradial <- predict(svmodelradial,newdata = tstSet)
table(svpredradial)

results.new_df <- rbind(results.new_df,allcrosstabmeasures(tst_labels,svpredradial,"Support Vector Machine (SVM) - Radial"))
results.new_df
```

Com os métodos Neural Network e Support Vector Machine (SVM) LINEAR, não foi possível classificar pois nunca foi capaz de prever o atributo do tipo frequente, logo não consideramos na nossa análise.




## Avaliacao dos modelos para previsao do atributo de cliente baseado no RFM.

                                    model    accuracy recall    precision   f1    kappa   fpr
                            C5.0 Classif.    0.376    0.103     0.308       0.154 0.248   0.097
            C5.0 with adaptative boosting    0.376    0.103     0.308       0.154 0.248   0.097
                              Naive Bayes    0.379    0.004     0.174       0.008 0.251   0.010
                     K-Nearest neighbours    0.374    0.044     0.289       0.076 0.223   0.044
    Support Vector Machine (SVM) - Radial    0.364    0.064     0.260       0.103 0.203   0.071



## References
