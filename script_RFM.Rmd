---
title: "DESCO - Knowledge Discovery"
author: "1141074 - Sérgio Silva | 1970400 - Pedro Neves | 1040706 - Sérgio Castro"
date: "5/3/2018"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Limpeza do ambiente

```{r Clean Environment}
rm(list = ls())
```

#Importes necessários

```{r}
library(lattice)
library(ggplot2)
library(caret)
library(C50)
library(data.table)
library(rfm)
library(lubridate)
library(gmodels)
library(e1071) #Nayve Bayes
```






#Carregamento das tabelas de transaction

The	 RFM	 (recency,	 frequency	 and	 monetary)	 model	 is	 the	 most	 widely	 used	 to	characterize customers	 because	 of its	 simplicity	and	good	 predictive	 capabilities.	 "Recency"	 represents	 the	time	since	the	last	purchase,	a	lower	value	corresponding	to	a	higher	probability	of	the	customer	making	a	repeat	 purchase.	 "Frequency"	 denotes	 the	 number	 of	 purchases	 within	 a	 specified	 time	 period;	 higher	frequency	indicates	higher	loyalty.	"Monetary"	means	 the	amount	of	money	spent	over this	specified	 time	period,	a	higher	value	indicates a	customer	that	the	company	should	focus on [2].

Loading of the tables to create model RFM
```{r Carregamento}
keycols <- c('Store', 'Date', 'Time', 'TransactionID')

transactions = fread('DATA-CRM/TRANSACTION.dat')
setkeyv(transactions, keycols)

trans_items = fread('DATA-CRM/TRANSACTION_ITEM.dat')
setkeyv(trans_items, keycols)

```

##Fazer 'join' das duas tabelas e remover observações contendo datas inválidas


```{r Merge}
Result <- merge(transactions, trans_items, all = TRUE)
Result[, Date := as.Date(as.character.Date(Date),"%Y%m%d")]
Result <- na.omit(Result, cols = "Date")
```


## Gerar RFM Score com package rfm

Calcula 'Recency', 'Frequency' e 'Monetary' a partir duma tabela de transações
```{r RFM algorithm}
analysis_date <- as.Date("2015-01-01")

orders <- Result[, .(CardID, Date, Amount)]
rfm_result <- rfm_table_order(orders, CardID, Date, Amount, analysis_date, recency_bins = 5, frequency_bins = 5, monetary_bins = 5)

summary(rfm_result)
str(rfm_result)

rfm_bar_chart(rfm_result)

rfm_histograms(rfm_result)

# Correlacionar a Frequência com o valor gasto
rfm_fm_plot(rfm_result)

# Correlacionar a data da última compra com a frequência de compra
rfm_rf_plot(rfm_result)

rfm_heatmap(rfm_result)
```

O valor de "Recency" é classificado numa escala de 1 a 5 em que o valor 5 é atribuido aos clientes que compraram mais recentemente.
O valor de "Frequency" usa uma escala de 1 a 5 para indicar com 5 o cliente que compra com mais frequência
Por fim, o valor de Monetary classifica, também com uma escala de 1 a 5, indicando com 5 os clientes que gastam mais valor.

As divisões dos cestos é feita com o valor por defeito de 5, que divide em os valores a cada 20% dos dados.

Caso fosse necessério o calculo dos atributos do algoritmo RFM, poderíamos usar as seguintes formulas. As mesmas não foram usadas pois usamos o package RFM que nos dá este calculo automaticamente.

Cálculo "Manual" das três dimensões do RFM
```{r}
# Frequency
rfm_requency <- Result[, .N, by = CardID]

# Monetary
rfm_monetary <- Result[ , .(Total = sum(Amount)), by = CardID]

# Recency
rfm_recency <- Result[, .(LatestOrder = max(Date)), by = CardID][, .(Recency = analysis_date - LatestOrder), by = CardID]
```


#1. Exploração e preparação dos dados


##Tabela BRAND.DAT
```{r BRAND.dat}
brand <- read.table("DATA-CRM/BRAND.dat", header = TRUE, sep = ",", dec = ",")
```

Verificação dos dados da tabela brand, tal como o número de colunas e linhas, bem como se os dados foram corretamente carregados.
```{r }
summary(brand)
dim(brand)
str(brand)

```

Verificar se a tabela possui dados nulos
```{r}
table(is.na(brand))
unique(brand)
table(duplicated(brand))
```



##Tabela CAMPAIGN.DAT
Carregamento da tabela CAMPAIGN.dat
```{r CAMPAIGN.dat}
campaign <- read.table("DATA-CRM/CAMPAIGN.dat", header = TRUE, sep = ",", dec = ",")
```

### Verificação dos dados da tabela campaign, tal como o número de colunas e linhas, bem como se os dados foram corretamente carregados.
```{r}
summary(campaign)
dim(campaign)
str(campaign)
```

###Verificar se a tabela possui dados nulos
```{r}
table(is.na(campaign))
unique(campaign)
table(duplicated(campaign))

```


## Tabela CARD.dat
```{r CARD.dat}
card <- read.table("DATA-CRM/CARD.dat", header = TRUE, sep = ",", dec = ",")
setDT(card)
```

### Verificação dos dados da tabela card, tal como o número de colunas e linhas, bem como se os dados foram corretamente carregados.
```{r}
summary(card)
dim(card)
str(card)
nrow(card[!complete.cases(card),])
```

### Tratar os dados nulos e errados nas colunas NumChildren e YoungestChild , pois tem valores negativos. No MaritalStatus há dados nulos que devem ser tratados também.

```{r}
card$NumChildren[card$NumChildren < 0] <- 0
table(card$NumChildren)
card$YoungestChild[card$YoungestChild < 0] <- 0
table(card$YoungestChild)


# Como existem observações que indicam ter filhos, mas depois o campo do número de filhos está a 0, decidimos alterar o atributo "HasChildren" para "N"
card[card$NumChildren == 0 & card$HasChildren == 'Y', .N]
card$HasChildren[card$NumChildren == 0] <- 'N'


# NumChildren>0 e HasChildren
card[card$NumChildren > 0 & card$HasChildren == 'N', .N]
card$HasChildren[card$NumChildren > 0] <- 'Y'

plot(card$NumChildren~card$HasChildren)

#TODO: o que colocar em YoungestChild quando HasChildren == 'N' (e NumChildren == 0)? 


# Verificamos que o MaritalStatus possui dados vazios
table(card$MaritalStatus)

card[MaritalStatus == "", MaritalStatus := "O"]
card$MaritalStatus <- droplevels(card$MaritalStatus)
```

### Verificar se a tabela Card possui dados nulos
```{r}
table(is.na(card))
unique(card)
table(duplicated(card))

```

## Tabela CATEGORY.dat
```{r}
category <- read.table("DATA-CRM/CATEGORY.dat", header = TRUE, sep = ",", dec = ",")
```

### Verificação dos dados da tabela category, tal como o número de colunas e linhas, bem como se os dados foram corretamente carregados.
```{r}
summary(category)
dim(category)
str(category)
```

### Verificar se a tabela possui dados nulos
```{r}
table(is.na(category))
```


## Tabela SUBCATEGORY.dat
```{r}
subcategory <- read.table("DATA-CRM/SUBCATEGORY.dat", header = TRUE, sep = ",", dec = ",")
```

### Verificação dos dados da tabela subcategory, tal como o némero de colunas e linhas, bem como se os dados foram corretamente carregados.
```{r}
summary(subcategory)
dim(subcategory)
str(subcategory)
```
### Verificar se a tabela possui dados nulos
```{r}
table(is.na(subcategory))
```


## Tabela ITEM.dat
```{r}
item <- read.table("DATA-CRM/ITEM.dat", header = TRUE, sep = ";")
```

### Verificação dos dados da tabela item, tal como o número de colunas e linhas, bem como se os dados foram corretamente carregados.
```{r}
summary(item)
dim(item)
str(item)
```

Verificar se a tabela possui dados nulos
```{r}
table(is.na(item))
```


#2. Pré-processamento dos dados

## Merge das tabelas

```{r juntar dados dos clientes}
df_card <- merge(card, rfm_result$rfm[,c(1,9)], by.x = 'CardID', by.y = 'customer_id')

df_card <- merge(df_card, campaign, by = 'CardID')

df_card[, CardStartDate := as.Date(as.character.Date(CardStartDate),"%Y%m%d")]

df_card[, DateOfBirth := as.Date(as.character.Date(DateOfBirth),"%Y%m%d")]

```

```{r criar as colunas com idade e anos de cliente}
# Criar a idade do cliente
yr = duration(num = 1, units = "years")
df_card[, age := round(interval(DateOfBirth, analysis_date)/yr,digits = 0)][]

# Anos de clientes
df_card[, clientYears := round(interval(CardStartDate, analysis_date)/yr,digits = 0)][]

summary(df_card)
```

```{r retirar id e código postal, CardStartDate e DateOfBirth}

df_card <- df_card[, c(2,3,6,8:15)]

# Mudar o atributo objetivo para o fim da tabela
df_card <- df_card[, c(1:8,10,11,9)]

str(df_card)


df_card$Gender <- factor(df_card$Gender, levels = c("F", "M"), labels = c("Feminino", "Masculino"))
df_card$MaritalStatus <- factor(df_card$MaritalStatus, levels = c("M", "S", "O"), labels = c("Casado", "Solteiro", "Outro"))
df_card$HasChildren <- factor(df_card$HasChildren, levels = c("Y", "N"), labels = c("Sim","Não"))
df_card$Responded <- factor(df_card$Responded, levels = c(TRUE, FALSE), labels = c("Sim","Não"))

```


## Visualização dos dados

```{r}



# Verificar a percentagem de clientes que responderam à campanha
barplot(table(df_card$Responded), ylim = c(0,10000), main = "Responded")

prop.table(table(df_card$Responded))*100


```



#3. Criação de modelos de Data-Mining


```{r}


allcrosstabmeasures <- function (tst_labels, pred_labels, modelname=""){
  if (length(unique(tst_labels)) == length(unique(pred_labels))) {
  ctmatrix <- CrossTable(tst_labels,pred_labels,prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE, dnn = c("Real","Predicted"))
  accuracy <- sum(diag(ctmatrix$t))/sum(ctmatrix$t)
  recall <- ctmatrix[[1]][1,1]/sum(ctmatrix[[1]][1,]) #TPR Recall
  precision <- ctmatrix[[1]][1,1]/sum(ctmatrix[[1]][,1])
  fpr <- ctmatrix[[1]][2,1]/sum(ctmatrix[[1]][2,])
  f1 <- 2*precision*recall/(precision+recall)
  pre <- (sum(ctmatrix[[1]][1,])/sum(ctmatrix$t)*sum(ctmatrix[[1]][,1])/sum(ctmatrix$t)) + (sum(ctmatrix[[1]][2,])/sum(ctmatrix$t)*sum(ctmatrix[[1]][,2])/sum(ctmatrix$t))
  kappa <- (accuracy - pre) / (1-pre)
  data.frame(model=modelname,accuracy=round(accuracy,digits = 3),recall=round(recall,digits = 3),precision=round(precision,digits = 3),f1=round(f1,digits = 3), kappa=round(kappa,digits = 3),fpr=round(fpr,digits = 3))
  }
}


# Declara um data frame para guardar os dados estatisticos

results.df <- data.frame(model = character(),
                         accuracy = double(),
                         recall = double(),
                         precision = double(),
                         f1 = double(),
                         kappa = double(),
                         fpr = double(),
                         stringsAsFactors = FALSE)


# Holdout stratified
   

set.seed(1576)

#create of stratified train/test partitions
train.idx <- createDataPartition(df_card$Responded, p = 0.7, list = F)

trainSet <- df_card[ train.idx, ]
tstSet <-   df_card[-train.idx, ]

train_labels <- trainSet$Responded
tst_labels <- tstSet$Responded

round(prop.table(table(train_labels))*100, digits = 2)
round(prop.table(table(tst_labels))*100, digits = 2)

ncols <- dim(trainSet)[2]
ctrl <- trainControl(method = "cv", number = 10)

```


```{r C5.0 com funcão treino}
##################################################################################

# C5.0 com funcão treino

modelLookup(model = "C5.0") # ver o que o model pede

#grade de parametros para otimizar o algoritmo

grid <- expand.grid(winnow = c(TRUE,FALSE), trials = c(1,2,10,15,20), model = "tree")
grid
set.seed(123)

C5model <- train(Responded ~ ., data = trainSet,
                 method = 'C5.0',
                 metric = 'Accuracy',
                 trControl = ctrl,
                 tuneGrid = grid)

C5model

trellis.par.set(caretTheme())
plot(C5model)


C5pred <- predict(C5model, tstSet)

results.df <- rbind(results.df, allcrosstabmeasures(tst_labels, C5pred, "C5.0 with train caret "))
```



```{r C5.0 with adaptative boosting}
##################################################################################

# C5.0 with adaptative boosting

set.seed(123)

boost100.model <- C5.0(trainSet[-ncols],trainSet$Responded, trials = 100)

summary(boost100.model)

boost100.pred <- predict(boost100.model,tstSet)

resutls.df <- rbind(results.df,allcrosstabmeasures(tst_labels,boost100.pred,"C5.0 with adaptative boosting "))


##################################################################################
```


```{r Naive Bayes}
##################################################################################

# Naive Bayes

set.seed(123)

Bayesmodel <- train(trainSet[,-ncols], trainSet$Churned,
                    method = "nb",
                    tuneGrid = data.frame(fL=1,usekernel=FALSE,adjust=1),
                    trControl = crtl)

Bayespred <- predict(Bayesmodel,testSet)

resutls.df <- rbind(resutls.df,allcrosstabmeasures(test_Labels,Bayespred,"Naive Bayes"))


##################################################################################
```


#4. Avaliação dos modelos
